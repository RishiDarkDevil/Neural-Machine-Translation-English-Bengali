{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-Machine-Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8DWGN5TBKT4kuImnpF8hX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting Google Drive"
      ],
      "metadata": {
        "id": "0dqNGaFLKKAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVenoImvJZs9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/IASNLP\""
      ],
      "metadata": {
        "id": "iNpRDc1-KMj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "PfWtwH6jKV-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "# !pip install --upgrade jax # --> Doesn't require GPU # --> Needed in Basic, Bigger Transformer and LSTM with Attention\n",
        "# !pip install jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html # Requires GPU # --> Needed in Basic, Bigger Transformer and LSTM with Attention\n",
        "# !pip install --upgrade -q jax # --> Needed in Basic, Bigger Transformer and LSTM with Attention\n",
        "# !pip install --upgrade -q jaxlib # --> Needed in Basic, Bigger Transformer and LSTM with Attention\n",
        "# !pip install --upgrade -q trax # --> Needed in Basic, Bigger Transformer and LSTM with Attention\n",
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "id": "THQjQh3IKSYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sentencepiece as spm\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Needed in Basic Transformer and Bigger Transformer and LSTM with Attention\n",
        "# import jax\n",
        "# import trax\n",
        "# from trax.data import inputs\n",
        "# from trax.fastmath import numpy as fnp\n",
        "# from trax import layers as tl\n",
        "# from trax.supervised import training\n",
        "# from trax.models import Transformer\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from functools import reduce\n",
        "from collections import Counter\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "BtRDGlTFKYkS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the Colab Runtime is set to Accelerator: TPU.\n",
        "import requests\n",
        "import os\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "  resp = requests.post(url)\n",
        "  TPU_DRIVER_MODE = 1\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)"
      ],
      "metadata": {
        "id": "-mlIIHTcxDjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cc017a-6153-48f6-fd87-51aaa28a1772"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grpc://10.13.197.50:8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Data Generator"
      ],
      "metadata": {
        "id": "dGSyrTxsdEwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the `train_data` and `train_dev_data` along with the SentencePiece BPE models for English and Bengali."
      ],
      "metadata": {
        "id": "vs3sicrGV62k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_dev_data = pd.read_csv(\"train_data.csv\")[['src', 'tgt']], pd.read_csv(\"train_dev.csv\")[['src', 'tgt']] \n",
        "test_val_data, test_data = pd.read_csv(\"test_val.csv\")[['src', 'tgt']], pd.read_csv(\"test_data.csv\")[['src', 'tgt']]\n",
        "sp_en_bpe, sp_ben_bpe = spm.SentencePieceProcessor(), spm.SentencePieceProcessor()\n",
        "sp_en_bpe.load('eng_bpe.model'); sp_ben_bpe.load('ben_bpe.model');"
      ],
      "metadata": {
        "id": "dwRB4a6-TMo6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions are taken from the data preprocessing part to get tokenized representation of sentences as well as detokenized sentences."
      ],
      "metadata": {
        "id": "RecOkU19WJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence, sp_model):\n",
        "    # We add the EOS token at the end of each encoded sentence\n",
        "    inputs = [sp_model.bos_id()] + sp_model.encode_as_ids(sentence) + [sp_model.eos_id()]\n",
        "    return np.reshape(np.array(inputs), [1, -1])\n",
        "def detokenize(tokenized, sp_model):\n",
        "    integers = np.squeeze(tokenized).tolist()\n",
        "    return sp_model.DecodeIdsWithCheck(integers[1:integers.index(sp_model.eos_id())])\n",
        "def data_generator(batch_size, src, tgt, maxlen=60, shuffle=False, verbose=False):\n",
        "    num_lines = len(src)\n",
        "    lines_index = [*range(num_lines)]\n",
        "    if shuffle:\n",
        "        np.random.shuffle(lines_index)\n",
        "    index = 0\n",
        "    while True:\n",
        "        buffer_src = list()\n",
        "        buffer_tgt = list() \n",
        "        max_len = 0 \n",
        "        for i in range(batch_size):\n",
        "            if index >= num_lines:\n",
        "                index = 0\n",
        "                if shuffle:\n",
        "                    np.random.shuffle(lines_index)\n",
        "            buffer_src.append(src[lines_index[index]])\n",
        "            buffer_tgt.append(tgt[lines_index[index]])\n",
        "            index += 1\n",
        "        batch_src = pad_sequences(buffer_src, maxlen = maxlen, padding='post', truncating='post')\n",
        "        batch_tgt = pad_sequences(buffer_tgt, maxlen = maxlen, padding='post', truncating='post')\n",
        "        if verbose: print(\"index=\", index)\n",
        "        yield((batch_src, batch_tgt))"
      ],
      "metadata": {
        "id": "BG712QbdjiDo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_train_data_enc = [np.squeeze(tokenize(train_data['src'].iloc[i], sp_en_bpe)) for i in range(train_data.shape[0])]\n",
        "tgt_train_data_enc = [np.squeeze(tokenize(train_data['tgt'].iloc[i], sp_ben_bpe)) for i in range(train_data.shape[0])]\n",
        "src_train_dev_data_enc = [np.squeeze(tokenize(train_dev_data['src'].iloc[i], sp_en_bpe)) for i in range(train_dev_data.shape[0])]\n",
        "tgt_train_dev_data_enc = [np.squeeze(tokenize(train_dev_data['tgt'].iloc[i], sp_ben_bpe)) for i in range(train_dev_data.shape[0])]\n",
        "src_test_val_data_enc = [np.squeeze(tokenize(test_val_data['src'].iloc[i], sp_en_bpe)) for i in range(test_val_data.shape[0])]\n",
        "tgt_test_val_data_enc = [np.squeeze(tokenize(test_val_data['tgt'].iloc[i], sp_ben_bpe)) for i in range(test_val_data.shape[0])]"
      ],
      "metadata": {
        "id": "sKWfGPHSkIiz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Generators for `train_data` and `train_dev_data`."
      ],
      "metadata": {
        "id": "4_IkM3sSZI0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = data_generator(256, src_train_data_enc, tgt_train_data_enc)\n",
        "train_dev_data_gen = data_generator(128, src_train_dev_data_enc, tgt_train_dev_data_enc)\n",
        "test_val_data_gen = data_generator(64, src_test_val_data_enc, tgt_test_val_data_enc)"
      ],
      "metadata": {
        "id": "l1j2-VXOo-Ys"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "daRvdVJNlYuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Transformer Based Models"
      ],
      "metadata": {
        "id": "oAjtw5l5oQVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Basic Transformer (Trax)"
      ],
      "metadata": {
        "id": "GjwwhLS5jojv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take `vocabulary size = 16000` for source and target.(Train the Sentence Piece model with 16000 vocab_size from Data-Preparation part before training this).\\\n",
        "Now, we are ready to train our first model. We will start by training a basic transformer model from scratch with:\n",
        "-  `embedding dimension = 256`\n",
        "-  `dense layer units = 512`\n",
        "-  `number of heads = 4`\n",
        "-  `number of encoder layers = number of decoder layers = 3`\n",
        "- `maximum number of tokens = 60`\n",
        "\n",
        "The model takes two inputs i.e. the source and corresponding target sentences as a tuple and results in two outputs.)"
      ],
      "metadata": {
        "id": "WgAcGVLjlbx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(input_vocab_size=16000, output_vocab_size=16000, d_model=256, d_ff=512, dropout = 0.1, n_heads=4, n_encoder_layers=3, n_decoder_layers=3, max_len=60, mode='train')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEdPj8fBkUQ9",
        "outputId": "0c0593ba-65ef-4686-e54a-1daf14ab4201"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Serial_in2_out2[\n",
              "  Select[0,1,1]_in2_out3\n",
              "  Branch_out2[\n",
              "    []\n",
              "    Serial[\n",
              "      PaddingMask(0)\n",
              "    ]\n",
              "  ]\n",
              "  Serial_in2_out2[\n",
              "    Embedding_16000_256\n",
              "    Dropout\n",
              "    PositionalEncoding\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    LayerNorm\n",
              "  ]\n",
              "  Select[2,1,0]_in3_out3\n",
              "  Serial[\n",
              "    ShiftRight(1)\n",
              "  ]\n",
              "  Embedding_16000_256\n",
              "  Dropout\n",
              "  PositionalEncoding\n",
              "  Branch_in2_out2[\n",
              "    []\n",
              "    EncoderDecoderMask_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  LayerNorm\n",
              "  Select[0]_in3\n",
              "  Dense_16000\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Bigger Transformer (Trax)"
      ],
      "metadata": {
        "id": "Tr5VFrjcgAYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take `vocabulary size = 32000` for source and target.\\\n",
        "Now, we are ready to train our first model. We will start by training a basic transformer model from scratch with:\n",
        "-  `embedding dimension = 256`\n",
        "-  `dense layer units = 512`\n",
        "-  `number of heads = 4`\n",
        "-  `number of encoder layers = number of decoder layers = 6`\n",
        "- `maximum number of tokens = 60`\n",
        "\n",
        "The model takes two inputs i.e. the source and corresponding target sentences as a tuple and results in two outputs.)"
      ],
      "metadata": {
        "id": "PUgWHuoti0Nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(input_vocab_size=32000, output_vocab_size=32000, d_model=256, d_ff=512, dropout = 0.3, n_heads=4, n_encoder_layers=6, n_decoder_layers=6, max_len=60, mode='train')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyv01OnWgwDt",
        "outputId": "a8a5987c-b306-4ab7-d044-bb0147eaea5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Serial_in2_out2[\n",
              "  Select[0,1,1]_in2_out3\n",
              "  Branch_out2[\n",
              "    []\n",
              "    Serial[\n",
              "      PaddingMask(0)\n",
              "    ]\n",
              "  ]\n",
              "  Serial_in2_out2[\n",
              "    Embedding_32000_256\n",
              "    Dropout\n",
              "    PositionalEncoding\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial_in2_out2[\n",
              "      Branch_in2_out3[\n",
              "        None\n",
              "        Serial_in2_out2[\n",
              "          LayerNorm\n",
              "          Serial_in2_out2[\n",
              "            _in2_out2\n",
              "            Serial_in2_out2[\n",
              "              Select[0,0,0]_out3\n",
              "              Serial_in4_out2[\n",
              "                _in4_out4\n",
              "                Serial_in4_out2[\n",
              "                  Parallel_in3_out3[\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                    Dense_256\n",
              "                  ]\n",
              "                  PureAttention_in4_out2\n",
              "                  Dense_256\n",
              "                ]\n",
              "                _in2_out2\n",
              "              ]\n",
              "            ]\n",
              "            _in2_out2\n",
              "          ]\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    Serial[\n",
              "      Branch_out2[\n",
              "        None\n",
              "        Serial[\n",
              "          LayerNorm\n",
              "          Dense_512\n",
              "          Serial[\n",
              "            Relu\n",
              "          ]\n",
              "          Dropout\n",
              "          Dense_256\n",
              "          Dropout\n",
              "        ]\n",
              "      ]\n",
              "      Add_in2\n",
              "    ]\n",
              "    LayerNorm\n",
              "  ]\n",
              "  Select[2,1,0]_in3_out3\n",
              "  Serial[\n",
              "    ShiftRight(1)\n",
              "  ]\n",
              "  Embedding_32000_256\n",
              "  Dropout\n",
              "  PositionalEncoding\n",
              "  Branch_in2_out2[\n",
              "    []\n",
              "    EncoderDecoderMask_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Serial[\n",
              "          Serial[\n",
              "            Serial[\n",
              "              Branch_out3[\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "                [Dense_256, Serial[\n",
              "                  SplitIntoHeads\n",
              "                ]]\n",
              "              ]\n",
              "              DotProductCausalAttention_in3\n",
              "              Serial[\n",
              "                MergeHeads\n",
              "              ]\n",
              "              Dense_256\n",
              "            ]\n",
              "          ]\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial_in3_out3[\n",
              "    Branch_in3_out4[\n",
              "      None\n",
              "      Serial_in3_out3[\n",
              "        LayerNorm\n",
              "        Select[0,2,2,1,2]_in3_out5\n",
              "        Serial_in4_out2[\n",
              "          _in4_out4\n",
              "          Serial_in4_out2[\n",
              "            Parallel_in3_out3[\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "              Dense_256\n",
              "            ]\n",
              "            PureAttention_in4_out2\n",
              "            Dense_256\n",
              "          ]\n",
              "          _in2_out2\n",
              "        ]\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Serial[\n",
              "    Branch_out2[\n",
              "      None\n",
              "      Serial[\n",
              "        LayerNorm\n",
              "        Dense_512\n",
              "        Serial[\n",
              "          Relu\n",
              "        ]\n",
              "        Dropout\n",
              "        Dense_256\n",
              "        Dropout\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  LayerNorm\n",
              "  Select[0]_in3\n",
              "  Dense_32000\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Training (Trax)"
      ],
      "metadata": {
        "id": "OuDkwt7ToNGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting our data generator to be fed to the training."
      ],
      "metadata": {
        "id": "ayJ8KiEkcrEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(43)\n",
        "train_generator = trax.data.inputs.add_loss_weights(train_data_gen, id_to_mask= sp_en_bpe.pad_id())\n",
        "train_dev_generator = trax.data.inputs.add_loss_weights(train_dev_data_gen, id_to_mask= sp_en_bpe.pad_id())\n",
        "test_val_generator = trax.data.inputs.add_loss_weights(test_val_data_gen, id_to_mask= sp_en_bpe.pad_id())"
      ],
      "metadata": {
        "id": "p3_51sXIrjo0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up `train_task` on which our model will be trained. We use:\n",
        "- `loss function = CrossEntropyLossWithLogSotmax`\n",
        "- `optimizer = Adam with learning rate 0.01`\n",
        "- `learning rate schedule = warm up and square root decay`."
      ],
      "metadata": {
        "id": "56uMNo9IczRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_task = training.TrainTask(labeled_data= train_generator, \n",
        "                                loss_layer= tl.CrossEntropyLossWithLogSoftmax(),\n",
        "                                optimizer= trax.optimizers.Adam(0.01),\n",
        "                                lr_schedule= trax.lr.warmup_and_rsqrt_decay(1000, 0.01),\n",
        "                                n_steps_per_checkpoint= 100,\n",
        "                                n_steps_per_permanent_checkpoint= 1000)"
      ],
      "metadata": {
        "id": "jN-P4002meBq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up `eval_task` for evaluating our model performance on `train_dev_data` and `test_val_data`. We monitor quite a few metrics on our evaluation datasets `train_dev_data` and `test_val_data` which are:\n",
        "- `CrossEntropyLossWithLogSoftmax`\n",
        "- `WeightedCategoryAccuracy`."
      ],
      "metadata": {
        "id": "JoeK7WZGdd_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_train_dev_task = training.EvalTask(labeled_data=train_dev_generator,\n",
        "                              metrics=[tl.CrossEntropyLossWithLogSoftmax(), tl.WeightedCategoryAccuracy()])"
      ],
      "metadata": {
        "id": "s2aLEm9-qo7W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test_val_task = training.EvalTask(labeled_data=test_val_generator,\n",
        "                              metrics=[tl.CrossEntropyLossWithLogSoftmax(), tl.WeightedCategoryAccuracy(), ])"
      ],
      "metadata": {
        "id": "Vc_iFcHHsl-9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the `training_loop` for training our model."
      ],
      "metadata": {
        "id": "VnlDe0kZeUGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = './Model-1'\n",
        "training_loop = training.Loop(model,\n",
        "                              train_task,\n",
        "                              eval_tasks=[eval_train_dev_task, eval_test_val_task],\n",
        "                              output_dir=output_dir)"
      ],
      "metadata": {
        "id": "taWsxxV1shCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_loop.run(5000) # -- Basic Transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT4I3ymcs5np",
        "outputId": "0275fd78-f9e8-4268-8762-ae4471a43820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step    100: Ran 99 train steps in 118.46 secs\n",
            "Step    100: train CrossEntropyLossWithLogSoftmax |  8.31935406\n",
            "Step    100: eval  CrossEntropyLossWithLogSoftmax |  7.54077768\n",
            "Step    100: eval        WeightedCategoryAccuracy |  0.10845987\n",
            "\n",
            "Step    200: Ran 100 train steps in 42.03 secs\n",
            "Step    200: train CrossEntropyLossWithLogSoftmax |  7.46800280\n",
            "Step    200: eval  CrossEntropyLossWithLogSoftmax |  6.85576916\n",
            "Step    200: eval        WeightedCategoryAccuracy |  0.16158536\n",
            "\n",
            "Step    300: Ran 100 train steps in 44.55 secs\n",
            "Step    300: train CrossEntropyLossWithLogSoftmax |  7.26776886\n",
            "Step    300: eval  CrossEntropyLossWithLogSoftmax |  7.23670197\n",
            "Step    300: eval        WeightedCategoryAccuracy |  0.10821643\n",
            "\n",
            "Step    400: Ran 100 train steps in 44.16 secs\n",
            "Step    400: train CrossEntropyLossWithLogSoftmax |  7.04190826\n",
            "Step    400: eval  CrossEntropyLossWithLogSoftmax |  6.91076279\n",
            "Step    400: eval        WeightedCategoryAccuracy |  0.15454544\n",
            "\n",
            "Step    500: Ran 100 train steps in 49.38 secs\n",
            "Step    500: train CrossEntropyLossWithLogSoftmax |  6.85026884\n",
            "Step    500: eval  CrossEntropyLossWithLogSoftmax |  6.76692724\n",
            "Step    500: eval        WeightedCategoryAccuracy |  0.13800904\n",
            "\n",
            "Step    600: Ran 100 train steps in 46.18 secs\n",
            "Step    600: train CrossEntropyLossWithLogSoftmax |  6.75522995\n",
            "Step    600: eval  CrossEntropyLossWithLogSoftmax |  6.28391933\n",
            "Step    600: eval        WeightedCategoryAccuracy |  0.15130024\n",
            "\n",
            "Step    700: Ran 100 train steps in 47.08 secs\n",
            "Step    700: train CrossEntropyLossWithLogSoftmax |  6.70708036\n",
            "Step    700: eval  CrossEntropyLossWithLogSoftmax |  6.73426151\n",
            "Step    700: eval        WeightedCategoryAccuracy |  0.13752456\n",
            "\n",
            "Step    800: Ran 100 train steps in 46.83 secs\n",
            "Step    800: train CrossEntropyLossWithLogSoftmax |  6.63746643\n",
            "Step    800: eval  CrossEntropyLossWithLogSoftmax |  6.61461496\n",
            "Step    800: eval        WeightedCategoryAccuracy |  0.13518885\n",
            "\n",
            "Step    900: Ran 100 train steps in 46.57 secs\n",
            "Step    900: train CrossEntropyLossWithLogSoftmax |  6.63621521\n",
            "Step    900: eval  CrossEntropyLossWithLogSoftmax |  6.64254951\n",
            "Step    900: eval        WeightedCategoryAccuracy |  0.12655601\n",
            "\n",
            "Step   1000: Ran 100 train steps in 62.38 secs\n",
            "Step   1000: train CrossEntropyLossWithLogSoftmax |  6.66851377\n",
            "Step   1000: eval  CrossEntropyLossWithLogSoftmax |  6.65040731\n",
            "Step   1000: eval        WeightedCategoryAccuracy |  0.13346612\n",
            "\n",
            "Step   1100: Ran 100 train steps in 46.61 secs\n",
            "Step   1100: train CrossEntropyLossWithLogSoftmax |  6.66310358\n",
            "Step   1100: eval  CrossEntropyLossWithLogSoftmax |  6.45758438\n",
            "Step   1100: eval        WeightedCategoryAccuracy |  0.14285715\n",
            "\n",
            "Step   1200: Ran 100 train steps in 46.42 secs\n",
            "Step   1200: train CrossEntropyLossWithLogSoftmax |  6.70834827\n",
            "Step   1200: eval  CrossEntropyLossWithLogSoftmax |  6.76600027\n",
            "Step   1200: eval        WeightedCategoryAccuracy |  0.14093959\n",
            "\n",
            "Step   1300: Ran 100 train steps in 45.66 secs\n",
            "Step   1300: train CrossEntropyLossWithLogSoftmax |  6.76428270\n",
            "Step   1300: eval  CrossEntropyLossWithLogSoftmax |  6.98154163\n",
            "Step   1300: eval        WeightedCategoryAccuracy |  0.12213740\n",
            "\n",
            "Step   1400: Ran 100 train steps in 46.33 secs\n",
            "Step   1400: train CrossEntropyLossWithLogSoftmax |  6.71470928\n",
            "Step   1400: eval  CrossEntropyLossWithLogSoftmax |  6.83534861\n",
            "Step   1400: eval        WeightedCategoryAccuracy |  0.13528335\n",
            "\n",
            "Step   1500: Ran 100 train steps in 46.92 secs\n",
            "Step   1500: train CrossEntropyLossWithLogSoftmax |  6.73487949\n",
            "Step   1500: eval  CrossEntropyLossWithLogSoftmax |  6.86508608\n",
            "Step   1500: eval        WeightedCategoryAccuracy |  0.11827958\n",
            "\n",
            "Step   1600: Ran 100 train steps in 46.53 secs\n",
            "Step   1600: train CrossEntropyLossWithLogSoftmax |  6.64171076\n",
            "Step   1600: eval  CrossEntropyLossWithLogSoftmax |  6.39392614\n",
            "Step   1600: eval        WeightedCategoryAccuracy |  0.15170941\n",
            "\n",
            "Step   1700: Ran 100 train steps in 49.84 secs\n",
            "Step   1700: train CrossEntropyLossWithLogSoftmax |  6.58204651\n",
            "Step   1700: eval  CrossEntropyLossWithLogSoftmax |  6.74156046\n",
            "Step   1700: eval        WeightedCategoryAccuracy |  0.12248996\n",
            "\n",
            "Step   1800: Ran 100 train steps in 46.51 secs\n",
            "Step   1800: train CrossEntropyLossWithLogSoftmax |  6.55308628\n",
            "Step   1800: eval  CrossEntropyLossWithLogSoftmax |  6.64200640\n",
            "Step   1800: eval        WeightedCategoryAccuracy |  0.15135135\n",
            "\n",
            "Step   1900: Ran 100 train steps in 46.91 secs\n",
            "Step   1900: train CrossEntropyLossWithLogSoftmax |  6.49758816\n",
            "Step   1900: eval  CrossEntropyLossWithLogSoftmax |  6.38030910\n",
            "Step   1900: eval        WeightedCategoryAccuracy |  0.14141415\n",
            "\n",
            "Step   2000: Ran 100 train steps in 63.00 secs\n",
            "Step   2000: train CrossEntropyLossWithLogSoftmax |  6.45555830\n",
            "Step   2000: eval  CrossEntropyLossWithLogSoftmax |  6.38528633\n",
            "Step   2000: eval        WeightedCategoryAccuracy |  0.15524194\n",
            "\n",
            "Step   2100: Ran 100 train steps in 44.66 secs\n",
            "Step   2100: train CrossEntropyLossWithLogSoftmax |  6.53307676\n",
            "Step   2100: eval  CrossEntropyLossWithLogSoftmax |  6.55288649\n",
            "Step   2100: eval        WeightedCategoryAccuracy |  0.14512922\n",
            "\n",
            "Step   2200: Ran 100 train steps in 46.89 secs\n",
            "Step   2200: train CrossEntropyLossWithLogSoftmax |  6.50069141\n",
            "Step   2200: eval  CrossEntropyLossWithLogSoftmax |  6.27098989\n",
            "Step   2200: eval        WeightedCategoryAccuracy |  0.16350710\n",
            "\n",
            "Step   2300: Ran 100 train steps in 46.78 secs\n",
            "Step   2300: train CrossEntropyLossWithLogSoftmax |  6.44813967\n",
            "Step   2300: eval  CrossEntropyLossWithLogSoftmax |  6.61070967\n",
            "Step   2300: eval        WeightedCategoryAccuracy |  0.12883435\n",
            "\n",
            "Step   2400: Ran 100 train steps in 46.89 secs\n",
            "Step   2400: train CrossEntropyLossWithLogSoftmax |  6.42998171\n",
            "Step   2400: eval  CrossEntropyLossWithLogSoftmax |  6.46818495\n",
            "Step   2400: eval        WeightedCategoryAccuracy |  0.13817330\n",
            "\n",
            "Step   2500: Ran 100 train steps in 48.94 secs\n",
            "Step   2500: train CrossEntropyLossWithLogSoftmax |  6.42006683\n",
            "Step   2500: eval  CrossEntropyLossWithLogSoftmax |  6.52923250\n",
            "Step   2500: eval        WeightedCategoryAccuracy |  0.15400845\n",
            "\n",
            "Step   2600: Ran 100 train steps in 46.93 secs\n",
            "Step   2600: train CrossEntropyLossWithLogSoftmax |  6.36983633\n",
            "Step   2600: eval  CrossEntropyLossWithLogSoftmax |  6.81838322\n",
            "Step   2600: eval        WeightedCategoryAccuracy |  0.11057693\n",
            "\n",
            "Step   2700: Ran 100 train steps in 47.39 secs\n",
            "Step   2700: train CrossEntropyLossWithLogSoftmax |  6.33394527\n",
            "Step   2700: eval  CrossEntropyLossWithLogSoftmax |  6.12622643\n",
            "Step   2700: eval        WeightedCategoryAccuracy |  0.15644822\n",
            "\n",
            "Step   2800: Ran 100 train steps in 47.81 secs\n",
            "Step   2800: train CrossEntropyLossWithLogSoftmax |  6.29130888\n",
            "Step   2800: eval  CrossEntropyLossWithLogSoftmax |  6.54176331\n",
            "Step   2800: eval        WeightedCategoryAccuracy |  0.14699793\n",
            "\n",
            "Step   2900: Ran 100 train steps in 46.33 secs\n",
            "Step   2900: train CrossEntropyLossWithLogSoftmax |  6.30167913\n",
            "Step   2900: eval  CrossEntropyLossWithLogSoftmax |  6.70105886\n",
            "Step   2900: eval        WeightedCategoryAccuracy |  0.10855263\n",
            "\n",
            "Step   3000: Ran 100 train steps in 69.34 secs\n",
            "Step   3000: train CrossEntropyLossWithLogSoftmax |  6.31136656\n",
            "Step   3000: eval  CrossEntropyLossWithLogSoftmax |  6.35142326\n",
            "Step   3000: eval        WeightedCategoryAccuracy |  0.14259598\n",
            "\n",
            "Step   3100: Ran 100 train steps in 46.22 secs\n",
            "Step   3100: train CrossEntropyLossWithLogSoftmax |  6.28035975\n",
            "Step   3100: eval  CrossEntropyLossWithLogSoftmax |  6.57754230\n",
            "Step   3100: eval        WeightedCategoryAccuracy |  0.11320755\n",
            "\n",
            "Step   3200: Ran 100 train steps in 47.06 secs\n",
            "Step   3200: train CrossEntropyLossWithLogSoftmax |  6.25712061\n",
            "Step   3200: eval  CrossEntropyLossWithLogSoftmax |  6.53685665\n",
            "Step   3200: eval        WeightedCategoryAccuracy |  0.13257575\n",
            "\n",
            "Step   3300: Ran 100 train steps in 45.09 secs\n",
            "Step   3300: train CrossEntropyLossWithLogSoftmax |  6.23385191\n",
            "Step   3300: eval  CrossEntropyLossWithLogSoftmax |  6.51651335\n",
            "Step   3300: eval        WeightedCategoryAccuracy |  0.13043478\n",
            "\n",
            "Step   3400: Ran 100 train steps in 45.54 secs\n",
            "Step   3400: train CrossEntropyLossWithLogSoftmax |  6.18685293\n",
            "Step   3400: eval  CrossEntropyLossWithLogSoftmax |  6.25954151\n",
            "Step   3400: eval        WeightedCategoryAccuracy |  0.16063347\n",
            "\n",
            "Step   3500: Ran 100 train steps in 44.51 secs\n",
            "Step   3500: train CrossEntropyLossWithLogSoftmax |  6.18585873\n",
            "Step   3500: eval  CrossEntropyLossWithLogSoftmax |  6.28540945\n",
            "Step   3500: eval        WeightedCategoryAccuracy |  0.14223194\n",
            "\n",
            "Step   3600: Ran 100 train steps in 44.28 secs\n",
            "Step   3600: train CrossEntropyLossWithLogSoftmax |  6.16408300\n",
            "Step   3600: eval  CrossEntropyLossWithLogSoftmax |  6.42665911\n",
            "Step   3600: eval        WeightedCategoryAccuracy |  0.16035634\n",
            "\n",
            "Step   3700: Ran 100 train steps in 46.94 secs\n",
            "Step   3700: train CrossEntropyLossWithLogSoftmax |  6.17006111\n",
            "Step   3700: eval  CrossEntropyLossWithLogSoftmax |  6.39340258\n",
            "Step   3700: eval        WeightedCategoryAccuracy |  0.13831776\n",
            "\n",
            "Step   3800: Ran 100 train steps in 45.01 secs\n",
            "Step   3800: train CrossEntropyLossWithLogSoftmax |  6.11562252\n",
            "Step   3800: eval  CrossEntropyLossWithLogSoftmax |  6.19241095\n",
            "Step   3800: eval        WeightedCategoryAccuracy |  0.16374269\n",
            "\n",
            "Step   3900: Ran 100 train steps in 44.87 secs\n",
            "Step   3900: train CrossEntropyLossWithLogSoftmax |  6.11037350\n",
            "Step   3900: eval  CrossEntropyLossWithLogSoftmax |  6.12615490\n",
            "Step   3900: eval        WeightedCategoryAccuracy |  0.15835142\n",
            "\n",
            "Step   4000: Ran 100 train steps in 64.55 secs\n",
            "Step   4000: train CrossEntropyLossWithLogSoftmax |  6.14899349\n",
            "Step   4000: eval  CrossEntropyLossWithLogSoftmax |  6.60676098\n",
            "Step   4000: eval        WeightedCategoryAccuracy |  0.11657558\n",
            "\n",
            "Step   4100: Ran 100 train steps in 46.11 secs\n",
            "Step   4100: train CrossEntropyLossWithLogSoftmax |  6.12641811\n",
            "Step   4100: eval  CrossEntropyLossWithLogSoftmax |  6.01506948\n",
            "Step   4100: eval        WeightedCategoryAccuracy |  0.15827337\n",
            "\n",
            "Step   4200: Ran 100 train steps in 54.92 secs\n",
            "Step   4200: train CrossEntropyLossWithLogSoftmax |  6.07385492\n",
            "Step   4200: eval  CrossEntropyLossWithLogSoftmax |  6.57605505\n",
            "Step   4200: eval        WeightedCategoryAccuracy |  0.13543598\n",
            "\n",
            "Step   4300: Ran 100 train steps in 44.88 secs\n",
            "Step   4300: train CrossEntropyLossWithLogSoftmax |  6.06408453\n",
            "Step   4300: eval  CrossEntropyLossWithLogSoftmax |  6.08047485\n",
            "Step   4300: eval        WeightedCategoryAccuracy |  0.16919740\n",
            "\n",
            "Step   4400: Ran 100 train steps in 46.37 secs\n",
            "Step   4400: train CrossEntropyLossWithLogSoftmax |  6.05565834\n",
            "Step   4400: eval  CrossEntropyLossWithLogSoftmax |  6.24004269\n",
            "Step   4400: eval        WeightedCategoryAccuracy |  0.13271606\n",
            "\n",
            "Step   4500: Ran 100 train steps in 50.10 secs\n",
            "Step   4500: train CrossEntropyLossWithLogSoftmax |  6.07676077\n",
            "Step   4500: eval  CrossEntropyLossWithLogSoftmax |  6.00420380\n",
            "Step   4500: eval        WeightedCategoryAccuracy |  0.13705586\n",
            "\n",
            "Step   4600: Ran 100 train steps in 44.86 secs\n",
            "Step   4600: train CrossEntropyLossWithLogSoftmax |  6.06068659\n",
            "Step   4600: eval  CrossEntropyLossWithLogSoftmax |  6.35389328\n",
            "Step   4600: eval        WeightedCategoryAccuracy |  0.13996626\n",
            "\n",
            "Step   4700: Ran 100 train steps in 48.78 secs\n",
            "Step   4700: train CrossEntropyLossWithLogSoftmax |  6.03268051\n",
            "Step   4700: eval  CrossEntropyLossWithLogSoftmax |  6.43542576\n",
            "Step   4700: eval        WeightedCategoryAccuracy |  0.17021276\n",
            "\n",
            "Step   4800: Ran 100 train steps in 44.73 secs\n",
            "Step   4800: train CrossEntropyLossWithLogSoftmax |  6.01520443\n",
            "Step   4800: eval  CrossEntropyLossWithLogSoftmax |  6.13410568\n",
            "Step   4800: eval        WeightedCategoryAccuracy |  0.13953489\n",
            "\n",
            "Step   4900: Ran 100 train steps in 45.97 secs\n",
            "Step   4900: train CrossEntropyLossWithLogSoftmax |  6.00201273\n",
            "Step   4900: eval  CrossEntropyLossWithLogSoftmax |  6.15552282\n",
            "Step   4900: eval        WeightedCategoryAccuracy |  0.16743121\n",
            "\n",
            "Step   5000: Ran 100 train steps in 64.15 secs\n",
            "Step   5000: train CrossEntropyLossWithLogSoftmax |  6.00123644\n",
            "Step   5000: eval  CrossEntropyLossWithLogSoftmax |  5.98688698\n",
            "Step   5000: eval        WeightedCategoryAccuracy |  0.13052632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "jax.default_backend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WpaxGtMc6p0E",
        "outputId": "d33144d6-651a-43c0-8720-49300dc64aa1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop.run(15000) # Bigger Transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O6FFQXm6c-e",
        "outputId": "80693a46-5515-4a23-c0c1-721bf1afeedd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 32547072\n",
            "Step      1: Ran 1 train steps in 211.16 secs\n",
            "Step      1: train CrossEntropyLossWithLogSoftmax |  10.36063194\n",
            "Step      1: eval  CrossEntropyLossWithLogSoftmax |  10.35689640\n",
            "Step      1: eval        WeightedCategoryAccuracy |  0.00000000\n",
            "Step      1: eval  CrossEntropyLossWithLogSoftmax |  10.36632061\n",
            "Step      1: eval        WeightedCategoryAccuracy |  0.00000000\n",
            "\n",
            "Step    100: Ran 99 train steps in 77.94 secs\n",
            "Step    100: train CrossEntropyLossWithLogSoftmax |  8.76878548\n",
            "Step    100: eval  CrossEntropyLossWithLogSoftmax |  7.48929882\n",
            "Step    100: eval        WeightedCategoryAccuracy |  0.10610933\n",
            "Step    100: eval  CrossEntropyLossWithLogSoftmax |  8.00431538\n",
            "Step    100: eval        WeightedCategoryAccuracy |  0.05882353\n",
            "\n",
            "Step    200: Ran 100 train steps in 82.94 secs\n",
            "Step    200: train CrossEntropyLossWithLogSoftmax |  7.74584150\n",
            "Step    200: eval  CrossEntropyLossWithLogSoftmax |  7.75866127\n",
            "Step    200: eval        WeightedCategoryAccuracy |  0.10869565\n",
            "Step    200: eval  CrossEntropyLossWithLogSoftmax |  8.04549980\n",
            "Step    200: eval        WeightedCategoryAccuracy |  0.11111111\n",
            "\n",
            "Step    300: Ran 100 train steps in 85.21 secs\n",
            "Step    300: train CrossEntropyLossWithLogSoftmax |  7.53861380\n",
            "Step    300: eval  CrossEntropyLossWithLogSoftmax |  7.50264168\n",
            "Step    300: eval        WeightedCategoryAccuracy |  0.14640200\n",
            "Step    300: eval  CrossEntropyLossWithLogSoftmax |  7.93943119\n",
            "Step    300: eval        WeightedCategoryAccuracy |  0.07692308\n",
            "\n",
            "Step    400: Ran 100 train steps in 88.93 secs\n",
            "Step    400: train CrossEntropyLossWithLogSoftmax |  7.40421295\n",
            "Step    400: eval  CrossEntropyLossWithLogSoftmax |  7.26208305\n",
            "Step    400: eval        WeightedCategoryAccuracy |  0.12171838\n",
            "Step    400: eval  CrossEntropyLossWithLogSoftmax |  7.48940229\n",
            "Step    400: eval        WeightedCategoryAccuracy |  0.14189190\n",
            "\n",
            "Step    500: Ran 100 train steps in 94.43 secs\n",
            "Step    500: train CrossEntropyLossWithLogSoftmax |  7.28668261\n",
            "Step    500: eval  CrossEntropyLossWithLogSoftmax |  6.83388710\n",
            "Step    500: eval        WeightedCategoryAccuracy |  0.13533835\n",
            "Step    500: eval  CrossEntropyLossWithLogSoftmax |  7.51805115\n",
            "Step    500: eval        WeightedCategoryAccuracy |  0.13496932\n",
            "\n",
            "Step    600: Ran 100 train steps in 90.25 secs\n",
            "Step    600: train CrossEntropyLossWithLogSoftmax |  7.15022469\n",
            "Step    600: eval  CrossEntropyLossWithLogSoftmax |  7.19773293\n",
            "Step    600: eval        WeightedCategoryAccuracy |  0.13445379\n",
            "Step    600: eval  CrossEntropyLossWithLogSoftmax |  7.86568165\n",
            "Step    600: eval        WeightedCategoryAccuracy |  0.08938547\n",
            "\n",
            "Step    700: Ran 100 train steps in 91.03 secs\n",
            "Step    700: train CrossEntropyLossWithLogSoftmax |  7.08708668\n",
            "Step    700: eval  CrossEntropyLossWithLogSoftmax |  7.05838537\n",
            "Step    700: eval        WeightedCategoryAccuracy |  0.13361169\n",
            "Step    700: eval  CrossEntropyLossWithLogSoftmax |  7.21759033\n",
            "Step    700: eval        WeightedCategoryAccuracy |  0.11971831\n",
            "\n",
            "Step    800: Ran 100 train steps in 93.25 secs\n",
            "Step    800: train CrossEntropyLossWithLogSoftmax |  7.05005169\n",
            "Step    800: eval  CrossEntropyLossWithLogSoftmax |  7.03000259\n",
            "Step    800: eval        WeightedCategoryAccuracy |  0.13716814\n",
            "Step    800: eval  CrossEntropyLossWithLogSoftmax |  7.57247257\n",
            "Step    800: eval        WeightedCategoryAccuracy |  0.10752688\n",
            "\n",
            "Step    900: Ran 100 train steps in 99.39 secs\n",
            "Step    900: train CrossEntropyLossWithLogSoftmax |  7.13093328\n",
            "Step    900: eval  CrossEntropyLossWithLogSoftmax |  7.14179945\n",
            "Step    900: eval        WeightedCategoryAccuracy |  0.12606838\n",
            "Step    900: eval  CrossEntropyLossWithLogSoftmax |  7.57539368\n",
            "Step    900: eval        WeightedCategoryAccuracy |  0.10439561\n",
            "\n",
            "Step   1000: Ran 100 train steps in 131.29 secs\n",
            "Step   1000: train CrossEntropyLossWithLogSoftmax |  7.22570419\n",
            "Step   1000: eval  CrossEntropyLossWithLogSoftmax |  7.12107658\n",
            "Step   1000: eval        WeightedCategoryAccuracy |  0.14823529\n",
            "Step   1000: eval  CrossEntropyLossWithLogSoftmax |  7.89874554\n",
            "Step   1000: eval        WeightedCategoryAccuracy |  0.07926829\n",
            "\n",
            "Step   1100: Ran 100 train steps in 99.68 secs\n",
            "Step   1100: train CrossEntropyLossWithLogSoftmax |  7.21958494\n",
            "Step   1100: eval  CrossEntropyLossWithLogSoftmax |  7.21057701\n",
            "Step   1100: eval        WeightedCategoryAccuracy |  0.15048544\n",
            "Step   1100: eval  CrossEntropyLossWithLogSoftmax |  7.53114939\n",
            "Step   1100: eval        WeightedCategoryAccuracy |  0.08152173\n",
            "\n",
            "Step   1200: Ran 100 train steps in 97.88 secs\n",
            "Step   1200: train CrossEntropyLossWithLogSoftmax |  7.19404411\n",
            "Step   1200: eval  CrossEntropyLossWithLogSoftmax |  7.32523584\n",
            "Step   1200: eval        WeightedCategoryAccuracy |  0.11336033\n",
            "Step   1200: eval  CrossEntropyLossWithLogSoftmax |  7.46752453\n",
            "Step   1200: eval        WeightedCategoryAccuracy |  0.13475177\n",
            "\n",
            "Step   1300: Ran 100 train steps in 98.68 secs\n",
            "Step   1300: train CrossEntropyLossWithLogSoftmax |  7.26256514\n",
            "Step   1300: eval  CrossEntropyLossWithLogSoftmax |  7.32769299\n",
            "Step   1300: eval        WeightedCategoryAccuracy |  0.11281070\n",
            "Step   1300: eval  CrossEntropyLossWithLogSoftmax |  7.64886856\n",
            "Step   1300: eval        WeightedCategoryAccuracy |  0.09352519\n",
            "\n",
            "Step   1400: Ran 100 train steps in 95.55 secs\n",
            "Step   1400: train CrossEntropyLossWithLogSoftmax |  7.25514650\n",
            "Step   1400: eval  CrossEntropyLossWithLogSoftmax |  7.29366589\n",
            "Step   1400: eval        WeightedCategoryAccuracy |  0.11516315\n",
            "Step   1400: eval  CrossEntropyLossWithLogSoftmax |  7.75182438\n",
            "Step   1400: eval        WeightedCategoryAccuracy |  0.11052631\n",
            "\n",
            "Step   1500: Ran 100 train steps in 98.93 secs\n",
            "Step   1500: train CrossEntropyLossWithLogSoftmax |  7.26150656\n",
            "Step   1500: eval  CrossEntropyLossWithLogSoftmax |  7.02576160\n",
            "Step   1500: eval        WeightedCategoryAccuracy |  0.13228700\n",
            "Step   1500: eval  CrossEntropyLossWithLogSoftmax |  7.41712999\n",
            "Step   1500: eval        WeightedCategoryAccuracy |  0.09039547\n",
            "\n",
            "Step   1600: Ran 100 train steps in 99.58 secs\n",
            "Step   1600: train CrossEntropyLossWithLogSoftmax |  7.28273582\n",
            "Step   1600: eval  CrossEntropyLossWithLogSoftmax |  7.49842215\n",
            "Step   1600: eval        WeightedCategoryAccuracy |  0.11827957\n",
            "Step   1600: eval  CrossEntropyLossWithLogSoftmax |  7.28495359\n",
            "Step   1600: eval        WeightedCategoryAccuracy |  0.10810811\n",
            "\n",
            "Step   1700: Ran 100 train steps in 95.92 secs\n",
            "Step   1700: train CrossEntropyLossWithLogSoftmax |  7.24476099\n",
            "Step   1700: eval  CrossEntropyLossWithLogSoftmax |  7.17135715\n",
            "Step   1700: eval        WeightedCategoryAccuracy |  0.12195121\n",
            "Step   1700: eval  CrossEntropyLossWithLogSoftmax |  7.76395559\n",
            "Step   1700: eval        WeightedCategoryAccuracy |  0.12179488\n",
            "\n",
            "Step   1800: Ran 100 train steps in 100.07 secs\n",
            "Step   1800: train CrossEntropyLossWithLogSoftmax |  7.26589966\n",
            "Step   1800: eval  CrossEntropyLossWithLogSoftmax |  6.98254061\n",
            "Step   1800: eval        WeightedCategoryAccuracy |  0.13978495\n",
            "Step   1800: eval  CrossEntropyLossWithLogSoftmax |  7.43781424\n",
            "Step   1800: eval        WeightedCategoryAccuracy |  0.12000000\n",
            "\n",
            "Step   1900: Ran 100 train steps in 102.52 secs\n",
            "Step   1900: train CrossEntropyLossWithLogSoftmax |  7.23117638\n",
            "Step   1900: eval  CrossEntropyLossWithLogSoftmax |  7.06201363\n",
            "Step   1900: eval        WeightedCategoryAccuracy |  0.14031181\n",
            "Step   1900: eval  CrossEntropyLossWithLogSoftmax |  7.51124430\n",
            "Step   1900: eval        WeightedCategoryAccuracy |  0.13740458\n",
            "\n",
            "Step   2000: Ran 100 train steps in 129.11 secs\n",
            "Step   2000: train CrossEntropyLossWithLogSoftmax |  7.22453880\n",
            "Step   2000: eval  CrossEntropyLossWithLogSoftmax |  7.35627222\n",
            "Step   2000: eval        WeightedCategoryAccuracy |  0.13232104\n",
            "Step   2000: eval  CrossEntropyLossWithLogSoftmax |  7.78078938\n",
            "Step   2000: eval        WeightedCategoryAccuracy |  0.10759493\n",
            "\n",
            "Step   2100: Ran 100 train steps in 99.68 secs\n",
            "Step   2100: train CrossEntropyLossWithLogSoftmax |  7.20307350\n",
            "Step   2100: eval  CrossEntropyLossWithLogSoftmax |  6.94880867\n",
            "Step   2100: eval        WeightedCategoryAccuracy |  0.14432989\n",
            "Step   2100: eval  CrossEntropyLossWithLogSoftmax |  7.55928135\n",
            "Step   2100: eval        WeightedCategoryAccuracy |  0.10000000\n",
            "\n",
            "Step   2200: Ran 100 train steps in 107.07 secs\n",
            "Step   2200: train CrossEntropyLossWithLogSoftmax |  7.19738197\n",
            "Step   2200: eval  CrossEntropyLossWithLogSoftmax |  7.22224998\n",
            "Step   2200: eval        WeightedCategoryAccuracy |  0.11622807\n",
            "Step   2200: eval  CrossEntropyLossWithLogSoftmax |  8.15227413\n",
            "Step   2200: eval        WeightedCategoryAccuracy |  0.08205128\n",
            "\n",
            "Step   2300: Ran 100 train steps in 115.83 secs\n",
            "Step   2300: train CrossEntropyLossWithLogSoftmax |  7.17475319\n",
            "Step   2300: eval  CrossEntropyLossWithLogSoftmax |  7.13707209\n",
            "Step   2300: eval        WeightedCategoryAccuracy |  0.14572863\n",
            "Step   2300: eval  CrossEntropyLossWithLogSoftmax |  7.58132601\n",
            "Step   2300: eval        WeightedCategoryAccuracy |  0.11428571\n",
            "\n",
            "Step   2400: Ran 100 train steps in 102.01 secs\n",
            "Step   2400: train CrossEntropyLossWithLogSoftmax |  7.18800116\n",
            "Step   2400: eval  CrossEntropyLossWithLogSoftmax |  7.04094744\n",
            "Step   2400: eval        WeightedCategoryAccuracy |  0.13258427\n",
            "Step   2400: eval  CrossEntropyLossWithLogSoftmax |  7.12484503\n",
            "Step   2400: eval        WeightedCategoryAccuracy |  0.13636363\n",
            "\n",
            "Step   2500: Ran 100 train steps in 104.71 secs\n",
            "Step   2500: train CrossEntropyLossWithLogSoftmax |  7.22483683\n",
            "Step   2500: eval  CrossEntropyLossWithLogSoftmax |  7.55798721\n",
            "Step   2500: eval        WeightedCategoryAccuracy |  0.08967852\n",
            "Step   2500: eval  CrossEntropyLossWithLogSoftmax |  7.55409384\n",
            "Step   2500: eval        WeightedCategoryAccuracy |  0.11029412\n",
            "\n",
            "Step   2600: Ran 100 train steps in 102.44 secs\n",
            "Step   2600: train CrossEntropyLossWithLogSoftmax |  7.27056074\n",
            "Step   2600: eval  CrossEntropyLossWithLogSoftmax |  7.07821512\n",
            "Step   2600: eval        WeightedCategoryAccuracy |  0.13363029\n",
            "Step   2600: eval  CrossEntropyLossWithLogSoftmax |  8.11098576\n",
            "Step   2600: eval        WeightedCategoryAccuracy |  0.07142857\n",
            "\n",
            "Step   2700: Ran 100 train steps in 104.64 secs\n",
            "Step   2700: train CrossEntropyLossWithLogSoftmax |  7.23210907\n",
            "Step   2700: eval  CrossEntropyLossWithLogSoftmax |  7.52113104\n",
            "Step   2700: eval        WeightedCategoryAccuracy |  0.12114537\n",
            "Step   2700: eval  CrossEntropyLossWithLogSoftmax |  7.31829929\n",
            "Step   2700: eval        WeightedCategoryAccuracy |  0.13157895\n",
            "\n",
            "Step   2800: Ran 100 train steps in 101.85 secs\n",
            "Step   2800: train CrossEntropyLossWithLogSoftmax |  7.23626280\n",
            "Step   2800: eval  CrossEntropyLossWithLogSoftmax |  7.46513605\n",
            "Step   2800: eval        WeightedCategoryAccuracy |  0.09294321\n",
            "Step   2800: eval  CrossEntropyLossWithLogSoftmax |  7.69311523\n",
            "Step   2800: eval        WeightedCategoryAccuracy |  0.10389610\n",
            "\n",
            "Step   2900: Ran 100 train steps in 113.28 secs\n",
            "Step   2900: train CrossEntropyLossWithLogSoftmax |  7.19381332\n",
            "Step   2900: eval  CrossEntropyLossWithLogSoftmax |  7.07042265\n",
            "Step   2900: eval        WeightedCategoryAccuracy |  0.11730769\n",
            "Step   2900: eval  CrossEntropyLossWithLogSoftmax |  7.67848110\n",
            "Step   2900: eval        WeightedCategoryAccuracy |  0.09523810\n",
            "\n",
            "Step   3000: Ran 100 train steps in 135.74 secs\n",
            "Step   3000: train CrossEntropyLossWithLogSoftmax |  7.16618109\n",
            "Step   3000: eval  CrossEntropyLossWithLogSoftmax |  7.32598305\n",
            "Step   3000: eval        WeightedCategoryAccuracy |  0.11069418\n",
            "Step   3000: eval  CrossEntropyLossWithLogSoftmax |  7.83536053\n",
            "Step   3000: eval        WeightedCategoryAccuracy |  0.10218978\n",
            "\n",
            "Step   3100: Ran 100 train steps in 97.84 secs\n",
            "Step   3100: train CrossEntropyLossWithLogSoftmax |  7.14867115\n",
            "Step   3100: eval  CrossEntropyLossWithLogSoftmax |  7.36243248\n",
            "Step   3100: eval        WeightedCategoryAccuracy |  0.11632653\n",
            "Step   3100: eval  CrossEntropyLossWithLogSoftmax |  7.59731579\n",
            "Step   3100: eval        WeightedCategoryAccuracy |  0.10204083\n",
            "\n",
            "Step   3200: Ran 100 train steps in 99.15 secs\n",
            "Step   3200: train CrossEntropyLossWithLogSoftmax |  7.12708950\n",
            "Step   3200: eval  CrossEntropyLossWithLogSoftmax |  7.30751514\n",
            "Step   3200: eval        WeightedCategoryAccuracy |  0.10918544\n",
            "Step   3200: eval  CrossEntropyLossWithLogSoftmax |  7.95376110\n",
            "Step   3200: eval        WeightedCategoryAccuracy |  0.10382514\n",
            "\n",
            "Step   3300: Ran 100 train steps in 101.43 secs\n",
            "Step   3300: train CrossEntropyLossWithLogSoftmax |  7.12318087\n",
            "Step   3300: eval  CrossEntropyLossWithLogSoftmax |  7.22249985\n",
            "Step   3300: eval        WeightedCategoryAccuracy |  0.15736040\n",
            "Step   3300: eval  CrossEntropyLossWithLogSoftmax |  7.71682405\n",
            "Step   3300: eval        WeightedCategoryAccuracy |  0.13071896\n",
            "\n",
            "Step   3400: Ran 100 train steps in 101.20 secs\n",
            "Step   3400: train CrossEntropyLossWithLogSoftmax |  7.10230160\n",
            "Step   3400: eval  CrossEntropyLossWithLogSoftmax |  6.96013165\n",
            "Step   3400: eval        WeightedCategoryAccuracy |  0.14252335\n",
            "Step   3400: eval  CrossEntropyLossWithLogSoftmax |  7.48930550\n",
            "Step   3400: eval        WeightedCategoryAccuracy |  0.12716763\n",
            "\n",
            "Step   3500: Ran 100 train steps in 110.89 secs\n",
            "Step   3500: train CrossEntropyLossWithLogSoftmax |  7.12367773\n",
            "Step   3500: eval  CrossEntropyLossWithLogSoftmax |  7.39865446\n",
            "Step   3500: eval        WeightedCategoryAccuracy |  0.12903227\n",
            "Step   3500: eval  CrossEntropyLossWithLogSoftmax |  7.61977911\n",
            "Step   3500: eval        WeightedCategoryAccuracy |  0.12949640\n",
            "\n",
            "Step   3600: Ran 100 train steps in 100.85 secs\n",
            "Step   3600: train CrossEntropyLossWithLogSoftmax |  7.13040066\n",
            "Step   3600: eval  CrossEntropyLossWithLogSoftmax |  7.14835358\n",
            "Step   3600: eval        WeightedCategoryAccuracy |  0.10934393\n",
            "Step   3600: eval  CrossEntropyLossWithLogSoftmax |  7.65993118\n",
            "Step   3600: eval        WeightedCategoryAccuracy |  0.10559005\n",
            "\n",
            "Step   3700: Ran 100 train steps in 102.26 secs\n",
            "Step   3700: train CrossEntropyLossWithLogSoftmax |  7.10444832\n",
            "Step   3700: eval  CrossEntropyLossWithLogSoftmax |  7.04976988\n",
            "Step   3700: eval        WeightedCategoryAccuracy |  0.14285713\n",
            "Step   3700: eval  CrossEntropyLossWithLogSoftmax |  7.42134142\n",
            "Step   3700: eval        WeightedCategoryAccuracy |  0.11258279\n",
            "\n",
            "Step   3800: Ran 100 train steps in 106.91 secs\n",
            "Step   3800: train CrossEntropyLossWithLogSoftmax |  7.12061548\n",
            "Step   3800: eval  CrossEntropyLossWithLogSoftmax |  6.90619278\n",
            "Step   3800: eval        WeightedCategoryAccuracy |  0.14691943\n",
            "Step   3800: eval  CrossEntropyLossWithLogSoftmax |  7.66252184\n",
            "Step   3800: eval        WeightedCategoryAccuracy |  0.12437811\n",
            "\n",
            "Step   3900: Ran 100 train steps in 104.88 secs\n",
            "Step   3900: train CrossEntropyLossWithLogSoftmax |  7.12132835\n",
            "Step   3900: eval  CrossEntropyLossWithLogSoftmax |  7.30259752\n",
            "Step   3900: eval        WeightedCategoryAccuracy |  0.12401575\n",
            "Step   3900: eval  CrossEntropyLossWithLogSoftmax |  7.28998327\n",
            "Step   3900: eval        WeightedCategoryAccuracy |  0.12179488\n",
            "\n",
            "Step   4000: Ran 100 train steps in 141.82 secs\n",
            "Step   4000: train CrossEntropyLossWithLogSoftmax |  7.09590006\n",
            "Step   4000: eval  CrossEntropyLossWithLogSoftmax |  6.81359482\n",
            "Step   4000: eval        WeightedCategoryAccuracy |  0.15721649\n",
            "Step   4000: eval  CrossEntropyLossWithLogSoftmax |  7.52361488\n",
            "Step   4000: eval        WeightedCategoryAccuracy |  0.13698632\n",
            "\n",
            "Step   4100: Ran 100 train steps in 99.14 secs\n",
            "Step   4100: train CrossEntropyLossWithLogSoftmax |  7.10163498\n",
            "Step   4100: eval  CrossEntropyLossWithLogSoftmax |  7.35319710\n",
            "Step   4100: eval        WeightedCategoryAccuracy |  0.11309525\n",
            "Step   4100: eval  CrossEntropyLossWithLogSoftmax |  7.26769257\n",
            "Step   4100: eval        WeightedCategoryAccuracy |  0.13194445\n",
            "\n",
            "Step   4200: Ran 100 train steps in 102.01 secs\n",
            "Step   4200: train CrossEntropyLossWithLogSoftmax |  7.07917881\n",
            "Step   4200: eval  CrossEntropyLossWithLogSoftmax |  6.87704182\n",
            "Step   4200: eval        WeightedCategoryAccuracy |  0.14350799\n",
            "Step   4200: eval  CrossEntropyLossWithLogSoftmax |  7.75869656\n",
            "Step   4200: eval        WeightedCategoryAccuracy |  0.10752688\n",
            "\n",
            "Step   4300: Ran 100 train steps in 103.18 secs\n",
            "Step   4300: train CrossEntropyLossWithLogSoftmax |  7.10926723\n",
            "Step   4300: eval  CrossEntropyLossWithLogSoftmax |  7.46734142\n",
            "Step   4300: eval        WeightedCategoryAccuracy |  0.09421487\n",
            "Step   4300: eval  CrossEntropyLossWithLogSoftmax |  7.56053114\n",
            "Step   4300: eval        WeightedCategoryAccuracy |  0.12500000\n",
            "\n",
            "Step   4400: Ran 100 train steps in 100.46 secs\n",
            "Step   4400: train CrossEntropyLossWithLogSoftmax |  7.06270552\n",
            "Step   4400: eval  CrossEntropyLossWithLogSoftmax |  6.62670898\n",
            "Step   4400: eval        WeightedCategoryAccuracy |  0.16157988\n",
            "Step   4400: eval  CrossEntropyLossWithLogSoftmax |  7.79319620\n",
            "Step   4400: eval        WeightedCategoryAccuracy |  0.12857144\n",
            "\n",
            "Step   4500: Ran 100 train steps in 102.06 secs\n",
            "Step   4500: train CrossEntropyLossWithLogSoftmax |  7.04853201\n",
            "Step   4500: eval  CrossEntropyLossWithLogSoftmax |  7.13323212\n",
            "Step   4500: eval        WeightedCategoryAccuracy |  0.12387791\n",
            "Step   4500: eval  CrossEntropyLossWithLogSoftmax |  7.62466478\n",
            "Step   4500: eval        WeightedCategoryAccuracy |  0.12903225\n",
            "\n",
            "Step   4600: Ran 100 train steps in 105.88 secs\n",
            "Step   4600: train CrossEntropyLossWithLogSoftmax |  7.02163124\n",
            "Step   4600: eval  CrossEntropyLossWithLogSoftmax |  7.07392263\n",
            "Step   4600: eval        WeightedCategoryAccuracy |  0.15601023\n",
            "Step   4600: eval  CrossEntropyLossWithLogSoftmax |  7.41617537\n",
            "Step   4600: eval        WeightedCategoryAccuracy |  0.12258064\n",
            "\n",
            "Step   4700: Ran 100 train steps in 101.65 secs\n",
            "Step   4700: train CrossEntropyLossWithLogSoftmax |  7.01137686\n",
            "Step   4700: eval  CrossEntropyLossWithLogSoftmax |  6.77750015\n",
            "Step   4700: eval        WeightedCategoryAccuracy |  0.13995485\n",
            "Step   4700: eval  CrossEntropyLossWithLogSoftmax |  7.16191673\n",
            "Step   4700: eval        WeightedCategoryAccuracy |  0.10493828\n",
            "\n",
            "Step   4800: Ran 100 train steps in 100.85 secs\n",
            "Step   4800: train CrossEntropyLossWithLogSoftmax |  7.00317812\n",
            "Step   4800: eval  CrossEntropyLossWithLogSoftmax |  6.89749193\n",
            "Step   4800: eval        WeightedCategoryAccuracy |  0.15270935\n",
            "Step   4800: eval  CrossEntropyLossWithLogSoftmax |  7.49256325\n",
            "Step   4800: eval        WeightedCategoryAccuracy |  0.11564626\n",
            "\n",
            "Step   4900: Ran 100 train steps in 99.83 secs\n",
            "Step   4900: train CrossEntropyLossWithLogSoftmax |  6.99310589\n",
            "Step   4900: eval  CrossEntropyLossWithLogSoftmax |  6.93792772\n",
            "Step   4900: eval        WeightedCategoryAccuracy |  0.12217194\n",
            "Step   4900: eval  CrossEntropyLossWithLogSoftmax |  7.85417700\n",
            "Step   4900: eval        WeightedCategoryAccuracy |  0.09004739\n",
            "\n",
            "Step   5000: Ran 100 train steps in 130.78 secs\n",
            "Step   5000: train CrossEntropyLossWithLogSoftmax |  6.98114681\n",
            "Step   5000: eval  CrossEntropyLossWithLogSoftmax |  6.92652702\n",
            "Step   5000: eval        WeightedCategoryAccuracy |  0.13362069\n",
            "Step   5000: eval  CrossEntropyLossWithLogSoftmax |  7.19927168\n",
            "Step   5000: eval        WeightedCategoryAccuracy |  0.11242604\n",
            "\n",
            "Step   5100: Ran 100 train steps in 101.88 secs\n",
            "Step   5100: train CrossEntropyLossWithLogSoftmax |  6.99287987\n",
            "Step   5100: eval  CrossEntropyLossWithLogSoftmax |  6.65756226\n",
            "Step   5100: eval        WeightedCategoryAccuracy |  0.18041237\n",
            "Step   5100: eval  CrossEntropyLossWithLogSoftmax |  7.33156776\n",
            "Step   5100: eval        WeightedCategoryAccuracy |  0.11688310\n",
            "\n",
            "Step   5200: Ran 100 train steps in 112.14 secs\n",
            "Step   5200: train CrossEntropyLossWithLogSoftmax |  7.01904106\n",
            "Step   5200: eval  CrossEntropyLossWithLogSoftmax |  6.95542383\n",
            "Step   5200: eval        WeightedCategoryAccuracy |  0.12987013\n",
            "Step   5200: eval  CrossEntropyLossWithLogSoftmax |  7.74205017\n",
            "Step   5200: eval        WeightedCategoryAccuracy |  0.10869564\n",
            "\n",
            "Step   5300: Ran 100 train steps in 100.76 secs\n",
            "Step   5300: train CrossEntropyLossWithLogSoftmax |  7.07096624\n",
            "Step   5300: eval  CrossEntropyLossWithLogSoftmax |  7.38281441\n",
            "Step   5300: eval        WeightedCategoryAccuracy |  0.13263159\n",
            "Step   5300: eval  CrossEntropyLossWithLogSoftmax |  7.64507961\n",
            "Step   5300: eval        WeightedCategoryAccuracy |  0.12676057\n",
            "\n",
            "Step   5400: Ran 100 train steps in 100.70 secs\n",
            "Step   5400: train CrossEntropyLossWithLogSoftmax |  7.03688383\n",
            "Step   5400: eval  CrossEntropyLossWithLogSoftmax |  6.86319876\n",
            "Step   5400: eval        WeightedCategoryAccuracy |  0.14609572\n",
            "Step   5400: eval  CrossEntropyLossWithLogSoftmax |  7.47800732\n",
            "Step   5400: eval        WeightedCategoryAccuracy |  0.12096774\n",
            "\n",
            "Step   5500: Ran 100 train steps in 103.04 secs\n",
            "Step   5500: train CrossEntropyLossWithLogSoftmax |  7.02244902\n",
            "Step   5500: eval  CrossEntropyLossWithLogSoftmax |  6.88589191\n",
            "Step   5500: eval        WeightedCategoryAccuracy |  0.14179105\n",
            "Step   5500: eval  CrossEntropyLossWithLogSoftmax |  7.70563745\n",
            "Step   5500: eval        WeightedCategoryAccuracy |  0.09195402\n",
            "\n",
            "Step   5600: Ran 100 train steps in 99.39 secs\n",
            "Step   5600: train CrossEntropyLossWithLogSoftmax |  7.00676823\n",
            "Step   5600: eval  CrossEntropyLossWithLogSoftmax |  6.94068336\n",
            "Step   5600: eval        WeightedCategoryAccuracy |  0.12354313\n",
            "Step   5600: eval  CrossEntropyLossWithLogSoftmax |  7.49876976\n",
            "Step   5600: eval        WeightedCategoryAccuracy |  0.09941521\n",
            "\n",
            "Step   5700: Ran 100 train steps in 101.32 secs\n",
            "Step   5700: train CrossEntropyLossWithLogSoftmax |  6.99109650\n",
            "Step   5700: eval  CrossEntropyLossWithLogSoftmax |  6.56796169\n",
            "Step   5700: eval        WeightedCategoryAccuracy |  0.19345237\n",
            "Step   5700: eval  CrossEntropyLossWithLogSoftmax |  7.45832491\n",
            "Step   5700: eval        WeightedCategoryAccuracy |  0.12418301\n",
            "\n",
            "Step   5800: Ran 100 train steps in 109.81 secs\n",
            "Step   5800: train CrossEntropyLossWithLogSoftmax |  7.01343727\n",
            "Step   5800: eval  CrossEntropyLossWithLogSoftmax |  7.12758636\n",
            "Step   5800: eval        WeightedCategoryAccuracy |  0.11702128\n",
            "Step   5800: eval  CrossEntropyLossWithLogSoftmax |  7.21786451\n",
            "Step   5800: eval        WeightedCategoryAccuracy |  0.15037593\n",
            "\n",
            "Step   5900: Ran 100 train steps in 103.84 secs\n",
            "Step   5900: train CrossEntropyLossWithLogSoftmax |  7.00128841\n",
            "Step   5900: eval  CrossEntropyLossWithLogSoftmax |  7.57808924\n",
            "Step   5900: eval        WeightedCategoryAccuracy |  0.11090910\n",
            "Step   5900: eval  CrossEntropyLossWithLogSoftmax |  7.51734447\n",
            "Step   5900: eval        WeightedCategoryAccuracy |  0.12337661\n",
            "\n",
            "Step   6000: Ran 100 train steps in 138.48 secs\n",
            "Step   6000: train CrossEntropyLossWithLogSoftmax |  6.98907566\n",
            "Step   6000: eval  CrossEntropyLossWithLogSoftmax |  7.15235901\n",
            "Step   6000: eval        WeightedCategoryAccuracy |  0.11507937\n",
            "Step   6000: eval  CrossEntropyLossWithLogSoftmax |  7.84803581\n",
            "Step   6000: eval        WeightedCategoryAccuracy |  0.11229946\n",
            "\n",
            "Step   6100: Ran 100 train steps in 99.34 secs\n",
            "Step   6100: train CrossEntropyLossWithLogSoftmax |  7.00613594\n",
            "Step   6100: eval  CrossEntropyLossWithLogSoftmax |  7.12251663\n",
            "Step   6100: eval        WeightedCategoryAccuracy |  0.12695312\n",
            "Step   6100: eval  CrossEntropyLossWithLogSoftmax |  7.41577005\n",
            "Step   6100: eval        WeightedCategoryAccuracy |  0.11258279\n",
            "\n",
            "Step   6200: Ran 100 train steps in 102.83 secs\n",
            "Step   6200: train CrossEntropyLossWithLogSoftmax |  6.97939110\n",
            "Step   6200: eval  CrossEntropyLossWithLogSoftmax |  7.30851650\n",
            "Step   6200: eval        WeightedCategoryAccuracy |  0.10380623\n",
            "Step   6200: eval  CrossEntropyLossWithLogSoftmax |  7.52371311\n",
            "Step   6200: eval        WeightedCategoryAccuracy |  0.12080537\n",
            "\n",
            "Step   6300: Ran 100 train steps in 110.12 secs\n",
            "Step   6300: train CrossEntropyLossWithLogSoftmax |  7.01450253\n",
            "Step   6300: eval  CrossEntropyLossWithLogSoftmax |  7.02990007\n",
            "Step   6300: eval        WeightedCategoryAccuracy |  0.11958764\n",
            "Step   6300: eval  CrossEntropyLossWithLogSoftmax |  7.41740465\n",
            "Step   6300: eval        WeightedCategoryAccuracy |  0.09523810\n",
            "\n",
            "Step   6400: Ran 100 train steps in 104.30 secs\n",
            "Step   6400: train CrossEntropyLossWithLogSoftmax |  7.00618649\n",
            "Step   6400: eval  CrossEntropyLossWithLogSoftmax |  6.88615417\n",
            "Step   6400: eval        WeightedCategoryAccuracy |  0.14754099\n",
            "Step   6400: eval  CrossEntropyLossWithLogSoftmax |  7.42818737\n",
            "Step   6400: eval        WeightedCategoryAccuracy |  0.13071896\n",
            "\n",
            "Step   6500: Ran 100 train steps in 104.78 secs\n",
            "Step   6500: train CrossEntropyLossWithLogSoftmax |  7.00065517\n",
            "Step   6500: eval  CrossEntropyLossWithLogSoftmax |  6.55476856\n",
            "Step   6500: eval        WeightedCategoryAccuracy |  0.13761470\n",
            "Step   6500: eval  CrossEntropyLossWithLogSoftmax |  7.40993595\n",
            "Step   6500: eval        WeightedCategoryAccuracy |  0.12138728\n",
            "\n",
            "Step   6600: Ran 100 train steps in 101.20 secs\n",
            "Step   6600: train CrossEntropyLossWithLogSoftmax |  6.98022985\n",
            "Step   6600: eval  CrossEntropyLossWithLogSoftmax |  7.33733463\n",
            "Step   6600: eval        WeightedCategoryAccuracy |  0.12248994\n",
            "Step   6600: eval  CrossEntropyLossWithLogSoftmax |  7.35374928\n",
            "Step   6600: eval        WeightedCategoryAccuracy |  0.11409397\n",
            "\n",
            "Step   6700: Ran 100 train steps in 102.97 secs\n",
            "Step   6700: train CrossEntropyLossWithLogSoftmax |  6.97687960\n",
            "Step   6700: eval  CrossEntropyLossWithLogSoftmax |  6.88371944\n",
            "Step   6700: eval        WeightedCategoryAccuracy |  0.13667427\n",
            "Step   6700: eval  CrossEntropyLossWithLogSoftmax |  7.59110832\n",
            "Step   6700: eval        WeightedCategoryAccuracy |  0.12500000\n",
            "\n",
            "Step   6800: Ran 100 train steps in 100.37 secs\n",
            "Step   6800: train CrossEntropyLossWithLogSoftmax |  6.95295191\n",
            "Step   6800: eval  CrossEntropyLossWithLogSoftmax |  7.23075867\n",
            "Step   6800: eval        WeightedCategoryAccuracy |  0.12573674\n",
            "Step   6800: eval  CrossEntropyLossWithLogSoftmax |  7.80849075\n",
            "Step   6800: eval        WeightedCategoryAccuracy |  0.09523810\n",
            "\n",
            "Step   6900: Ran 100 train steps in 110.88 secs\n",
            "Step   6900: train CrossEntropyLossWithLogSoftmax |  6.95099163\n",
            "Step   6900: eval  CrossEntropyLossWithLogSoftmax |  6.92151308\n",
            "Step   6900: eval        WeightedCategoryAccuracy |  0.12842105\n",
            "Step   6900: eval  CrossEntropyLossWithLogSoftmax |  7.62555933\n",
            "Step   6900: eval        WeightedCategoryAccuracy |  0.12179488\n",
            "\n",
            "Step   7000: Ran 100 train steps in 135.09 secs\n",
            "Step   7000: train CrossEntropyLossWithLogSoftmax |  6.95359421\n",
            "Step   7000: eval  CrossEntropyLossWithLogSoftmax |  7.17714024\n",
            "Step   7000: eval        WeightedCategoryAccuracy |  0.13608249\n",
            "Step   7000: eval  CrossEntropyLossWithLogSoftmax |  7.37722445\n",
            "Step   7000: eval        WeightedCategoryAccuracy |  0.11797753\n",
            "\n",
            "Step   7100: Ran 100 train steps in 104.49 secs\n",
            "Step   7100: train CrossEntropyLossWithLogSoftmax |  6.95404959\n",
            "Step   7100: eval  CrossEntropyLossWithLogSoftmax |  7.06649828\n",
            "Step   7100: eval        WeightedCategoryAccuracy |  0.12576064\n",
            "Step   7100: eval  CrossEntropyLossWithLogSoftmax |  7.04731846\n",
            "Step   7100: eval        WeightedCategoryAccuracy |  0.12903225\n",
            "\n",
            "Step   7200: Ran 100 train steps in 105.95 secs\n",
            "Step   7200: train CrossEntropyLossWithLogSoftmax |  6.96172571\n",
            "Step   7200: eval  CrossEntropyLossWithLogSoftmax |  7.08680725\n",
            "Step   7200: eval        WeightedCategoryAccuracy |  0.13432835\n",
            "Step   7200: eval  CrossEntropyLossWithLogSoftmax |  7.41694975\n",
            "Step   7200: eval        WeightedCategoryAccuracy |  0.11538462\n",
            "\n",
            "Step   7300: Ran 100 train steps in 102.98 secs\n",
            "Step   7300: train CrossEntropyLossWithLogSoftmax |  6.95046234\n",
            "Step   7300: eval  CrossEntropyLossWithLogSoftmax |  6.96464920\n",
            "Step   7300: eval        WeightedCategoryAccuracy |  0.12601626\n",
            "Step   7300: eval  CrossEntropyLossWithLogSoftmax |  7.19263124\n",
            "Step   7300: eval        WeightedCategoryAccuracy |  0.14925373\n",
            "\n",
            "Step   7400: Ran 100 train steps in 104.62 secs\n",
            "Step   7400: train CrossEntropyLossWithLogSoftmax |  6.93995953\n",
            "Step   7400: eval  CrossEntropyLossWithLogSoftmax |  7.17721462\n",
            "Step   7400: eval        WeightedCategoryAccuracy |  0.12578616\n",
            "Step   7400: eval  CrossEntropyLossWithLogSoftmax |  7.42667055\n",
            "Step   7400: eval        WeightedCategoryAccuracy |  0.11971831\n",
            "\n",
            "Step   7500: Ran 100 train steps in 109.18 secs\n",
            "Step   7500: train CrossEntropyLossWithLogSoftmax |  6.95115423\n",
            "Step   7500: eval  CrossEntropyLossWithLogSoftmax |  6.85088539\n",
            "Step   7500: eval        WeightedCategoryAccuracy |  0.15618221\n",
            "Step   7500: eval  CrossEntropyLossWithLogSoftmax |  7.33160782\n",
            "Step   7500: eval        WeightedCategoryAccuracy |  0.10285714\n",
            "\n",
            "Step   7600: Ran 100 train steps in 106.70 secs\n",
            "Step   7600: train CrossEntropyLossWithLogSoftmax |  6.93837643\n",
            "Step   7600: eval  CrossEntropyLossWithLogSoftmax |  6.72053242\n",
            "Step   7600: eval        WeightedCategoryAccuracy |  0.13769752\n",
            "Step   7600: eval  CrossEntropyLossWithLogSoftmax |  7.27294350\n",
            "Step   7600: eval        WeightedCategoryAccuracy |  0.13207546\n",
            "\n",
            "Step   7700: Ran 100 train steps in 105.09 secs\n",
            "Step   7700: train CrossEntropyLossWithLogSoftmax |  6.96952438\n",
            "Step   7700: eval  CrossEntropyLossWithLogSoftmax |  7.14275503\n",
            "Step   7700: eval        WeightedCategoryAccuracy |  0.13406593\n",
            "Step   7700: eval  CrossEntropyLossWithLogSoftmax |  7.79576015\n",
            "Step   7700: eval        WeightedCategoryAccuracy |  0.08196722\n",
            "\n",
            "Step   7800: Ran 100 train steps in 104.31 secs\n",
            "Step   7800: train CrossEntropyLossWithLogSoftmax |  6.94786787\n",
            "Step   7800: eval  CrossEntropyLossWithLogSoftmax |  7.04239178\n",
            "Step   7800: eval        WeightedCategoryAccuracy |  0.10157618\n",
            "Step   7800: eval  CrossEntropyLossWithLogSoftmax |  7.30285549\n",
            "Step   7800: eval        WeightedCategoryAccuracy |  0.13253012\n",
            "\n",
            "Step   7900: Ran 100 train steps in 104.46 secs\n",
            "Step   7900: train CrossEntropyLossWithLogSoftmax |  6.94934320\n",
            "Step   7900: eval  CrossEntropyLossWithLogSoftmax |  6.83549881\n",
            "Step   7900: eval        WeightedCategoryAccuracy |  0.15638766\n",
            "Step   7900: eval  CrossEntropyLossWithLogSoftmax |  7.68124008\n",
            "Step   7900: eval        WeightedCategoryAccuracy |  0.10344827\n",
            "\n",
            "Step   8000: Ran 100 train steps in 147.45 secs\n",
            "Step   8000: train CrossEntropyLossWithLogSoftmax |  6.92043209\n",
            "Step   8000: eval  CrossEntropyLossWithLogSoftmax |  6.82480049\n",
            "Step   8000: eval        WeightedCategoryAccuracy |  0.14814815\n",
            "Step   8000: eval  CrossEntropyLossWithLogSoftmax |  7.62991047\n",
            "Step   8000: eval        WeightedCategoryAccuracy |  0.10344827\n",
            "\n",
            "Step   8100: Ran 100 train steps in 97.59 secs\n",
            "Step   8100: train CrossEntropyLossWithLogSoftmax |  6.90009546\n",
            "Step   8100: eval  CrossEntropyLossWithLogSoftmax |  6.68615437\n",
            "Step   8100: eval        WeightedCategoryAccuracy |  0.16897506\n",
            "Step   8100: eval  CrossEntropyLossWithLogSoftmax |  7.09666252\n",
            "Step   8100: eval        WeightedCategoryAccuracy |  0.14965987\n",
            "\n",
            "Step   8200: Ran 100 train steps in 101.14 secs\n",
            "Step   8200: train CrossEntropyLossWithLogSoftmax |  6.89274454\n",
            "Step   8200: eval  CrossEntropyLossWithLogSoftmax |  7.12049770\n",
            "Step   8200: eval        WeightedCategoryAccuracy |  0.11422846\n",
            "Step   8200: eval  CrossEntropyLossWithLogSoftmax |  7.40624714\n",
            "Step   8200: eval        WeightedCategoryAccuracy |  0.09815951\n",
            "\n",
            "Step   8300: Ran 100 train steps in 99.91 secs\n",
            "Step   8300: train CrossEntropyLossWithLogSoftmax |  6.87534571\n",
            "Step   8300: eval  CrossEntropyLossWithLogSoftmax |  6.67784595\n",
            "Step   8300: eval        WeightedCategoryAccuracy |  0.14988813\n",
            "Step   8300: eval  CrossEntropyLossWithLogSoftmax |  7.37940025\n",
            "Step   8300: eval        WeightedCategoryAccuracy |  0.12804878\n",
            "\n",
            "Step   8400: Ran 100 train steps in 102.74 secs\n",
            "Step   8400: train CrossEntropyLossWithLogSoftmax |  6.89242792\n",
            "Step   8400: eval  CrossEntropyLossWithLogSoftmax |  7.15168953\n",
            "Step   8400: eval        WeightedCategoryAccuracy |  0.12391303\n",
            "Step   8400: eval  CrossEntropyLossWithLogSoftmax |  7.69346285\n",
            "Step   8400: eval        WeightedCategoryAccuracy |  0.10919540\n",
            "\n",
            "Step   8500: Ran 100 train steps in 100.03 secs\n",
            "Step   8500: train CrossEntropyLossWithLogSoftmax |  6.88979292\n",
            "Step   8500: eval  CrossEntropyLossWithLogSoftmax |  6.86793995\n",
            "Step   8500: eval        WeightedCategoryAccuracy |  0.16216215\n",
            "Step   8500: eval  CrossEntropyLossWithLogSoftmax |  7.40591908\n",
            "Step   8500: eval        WeightedCategoryAccuracy |  0.12101911\n",
            "\n",
            "Step   8600: Ran 100 train steps in 107.88 secs\n",
            "Step   8600: train CrossEntropyLossWithLogSoftmax |  6.87211370\n",
            "Step   8600: eval  CrossEntropyLossWithLogSoftmax |  6.72421360\n",
            "Step   8600: eval        WeightedCategoryAccuracy |  0.13817330\n",
            "Step   8600: eval  CrossEntropyLossWithLogSoftmax |  7.76583242\n",
            "Step   8600: eval        WeightedCategoryAccuracy |  0.10975610\n",
            "\n",
            "Step   8700: Ran 100 train steps in 102.93 secs\n",
            "Step   8700: train CrossEntropyLossWithLogSoftmax |  6.87576151\n",
            "Step   8700: eval  CrossEntropyLossWithLogSoftmax |  7.26224518\n",
            "Step   8700: eval        WeightedCategoryAccuracy |  0.11247803\n",
            "Step   8700: eval  CrossEntropyLossWithLogSoftmax |  7.72700882\n",
            "Step   8700: eval        WeightedCategoryAccuracy |  0.12804878\n",
            "\n",
            "Step   8800: Ran 100 train steps in 100.00 secs\n",
            "Step   8800: train CrossEntropyLossWithLogSoftmax |  6.86739445\n",
            "Step   8800: eval  CrossEntropyLossWithLogSoftmax |  7.13741779\n",
            "Step   8800: eval        WeightedCategoryAccuracy |  0.12068965\n",
            "Step   8800: eval  CrossEntropyLossWithLogSoftmax |  7.49466372\n",
            "Step   8800: eval        WeightedCategoryAccuracy |  0.12299465\n",
            "\n",
            "Step   8900: Ran 100 train steps in 103.90 secs\n",
            "Step   8900: train CrossEntropyLossWithLogSoftmax |  6.87348557\n",
            "Step   8900: eval  CrossEntropyLossWithLogSoftmax |  6.84439039\n",
            "Step   8900: eval        WeightedCategoryAccuracy |  0.14159292\n",
            "Step   8900: eval  CrossEntropyLossWithLogSoftmax |  7.80005121\n",
            "Step   8900: eval        WeightedCategoryAccuracy |  0.12209302\n",
            "\n",
            "Step   9000: Ran 100 train steps in 137.87 secs\n",
            "Step   9000: train CrossEntropyLossWithLogSoftmax |  6.83873987\n",
            "Step   9000: eval  CrossEntropyLossWithLogSoftmax |  6.98313904\n",
            "Step   9000: eval        WeightedCategoryAccuracy |  0.12098298\n",
            "Step   9000: eval  CrossEntropyLossWithLogSoftmax |  7.46366692\n",
            "Step   9000: eval        WeightedCategoryAccuracy |  0.15286624\n",
            "\n",
            "Step   9100: Ran 100 train steps in 97.63 secs\n",
            "Step   9100: train CrossEntropyLossWithLogSoftmax |  6.82056856\n",
            "Step   9100: eval  CrossEntropyLossWithLogSoftmax |  6.95376301\n",
            "Step   9100: eval        WeightedCategoryAccuracy |  0.15789473\n",
            "Step   9100: eval  CrossEntropyLossWithLogSoftmax |  7.74520206\n",
            "Step   9100: eval        WeightedCategoryAccuracy |  0.09756097\n",
            "\n",
            "Step   9200: Ran 100 train steps in 106.88 secs\n",
            "Step   9200: train CrossEntropyLossWithLogSoftmax |  6.81156063\n",
            "Step   9200: eval  CrossEntropyLossWithLogSoftmax |  6.83602476\n",
            "Step   9200: eval        WeightedCategoryAccuracy |  0.14777328\n",
            "Step   9200: eval  CrossEntropyLossWithLogSoftmax |  7.26118565\n",
            "Step   9200: eval        WeightedCategoryAccuracy |  0.09411766\n",
            "\n",
            "Step   9300: Ran 100 train steps in 102.31 secs\n",
            "Step   9300: train CrossEntropyLossWithLogSoftmax |  6.79719973\n",
            "Step   9300: eval  CrossEntropyLossWithLogSoftmax |  7.05028582\n",
            "Step   9300: eval        WeightedCategoryAccuracy |  0.14722754\n",
            "Step   9300: eval  CrossEntropyLossWithLogSoftmax |  6.92213631\n",
            "Step   9300: eval        WeightedCategoryAccuracy |  0.14074074\n",
            "\n",
            "Step   9400: Ran 100 train steps in 103.68 secs\n",
            "Step   9400: train CrossEntropyLossWithLogSoftmax |  6.82009459\n",
            "Step   9400: eval  CrossEntropyLossWithLogSoftmax |  7.03062153\n",
            "Step   9400: eval        WeightedCategoryAccuracy |  0.13025211\n",
            "Step   9400: eval  CrossEntropyLossWithLogSoftmax |  7.70940113\n",
            "Step   9400: eval        WeightedCategoryAccuracy |  0.09090909\n",
            "\n",
            "Step   9500: Ran 100 train steps in 105.71 secs\n",
            "Step   9500: train CrossEntropyLossWithLogSoftmax |  6.81081343\n",
            "Step   9500: eval  CrossEntropyLossWithLogSoftmax |  6.67546988\n",
            "Step   9500: eval        WeightedCategoryAccuracy |  0.16037735\n",
            "Step   9500: eval  CrossEntropyLossWithLogSoftmax |  7.12649441\n",
            "Step   9500: eval        WeightedCategoryAccuracy |  0.13194445\n",
            "\n",
            "Step   9600: Ran 100 train steps in 105.80 secs\n",
            "Step   9600: train CrossEntropyLossWithLogSoftmax |  6.80232716\n",
            "Step   9600: eval  CrossEntropyLossWithLogSoftmax |  6.99672747\n",
            "Step   9600: eval        WeightedCategoryAccuracy |  0.14252335\n",
            "Step   9600: eval  CrossEntropyLossWithLogSoftmax |  7.55527544\n",
            "Step   9600: eval        WeightedCategoryAccuracy |  0.11111112\n",
            "\n",
            "Step   9700: Ran 100 train steps in 109.77 secs\n",
            "Step   9700: train CrossEntropyLossWithLogSoftmax |  6.80208349\n",
            "Step   9700: eval  CrossEntropyLossWithLogSoftmax |  6.92309427\n",
            "Step   9700: eval        WeightedCategoryAccuracy |  0.11025145\n",
            "Step   9700: eval  CrossEntropyLossWithLogSoftmax |  7.41008854\n",
            "Step   9700: eval        WeightedCategoryAccuracy |  0.13669065\n",
            "\n",
            "Step   9800: Ran 100 train steps in 101.13 secs\n",
            "Step   9800: train CrossEntropyLossWithLogSoftmax |  6.81825447\n",
            "Step   9800: eval  CrossEntropyLossWithLogSoftmax |  6.92713594\n",
            "Step   9800: eval        WeightedCategoryAccuracy |  0.14187643\n",
            "Step   9800: eval  CrossEntropyLossWithLogSoftmax |  7.26216698\n",
            "Step   9800: eval        WeightedCategoryAccuracy |  0.10937500\n",
            "\n",
            "Step   9900: Ran 100 train steps in 105.15 secs\n",
            "Step   9900: train CrossEntropyLossWithLogSoftmax |  6.84626818\n",
            "Step   9900: eval  CrossEntropyLossWithLogSoftmax |  6.75694323\n",
            "Step   9900: eval        WeightedCategoryAccuracy |  0.12449799\n",
            "Step   9900: eval  CrossEntropyLossWithLogSoftmax |  7.42240334\n",
            "Step   9900: eval        WeightedCategoryAccuracy |  0.12751679\n",
            "\n",
            "Step  10000: Ran 100 train steps in 141.28 secs\n",
            "Step  10000: train CrossEntropyLossWithLogSoftmax |  6.89174414\n",
            "Step  10000: eval  CrossEntropyLossWithLogSoftmax |  6.72769165\n",
            "Step  10000: eval        WeightedCategoryAccuracy |  0.13698632\n",
            "Step  10000: eval  CrossEntropyLossWithLogSoftmax |  7.43861580\n",
            "Step  10000: eval        WeightedCategoryAccuracy |  0.12500000\n",
            "\n",
            "Step  10100: Ran 100 train steps in 98.79 secs\n",
            "Step  10100: train CrossEntropyLossWithLogSoftmax |  6.87100220\n",
            "Step  10100: eval  CrossEntropyLossWithLogSoftmax |  6.58295059\n",
            "Step  10100: eval        WeightedCategoryAccuracy |  0.14841849\n",
            "Step  10100: eval  CrossEntropyLossWithLogSoftmax |  7.38633919\n",
            "Step  10100: eval        WeightedCategoryAccuracy |  0.12903225\n",
            "\n",
            "Step  10200: Ran 100 train steps in 102.40 secs\n",
            "Step  10200: train CrossEntropyLossWithLogSoftmax |  6.83244419\n",
            "Step  10200: eval  CrossEntropyLossWithLogSoftmax |  6.83910465\n",
            "Step  10200: eval        WeightedCategoryAccuracy |  0.15641026\n",
            "Step  10200: eval  CrossEntropyLossWithLogSoftmax |  7.30761051\n",
            "Step  10200: eval        WeightedCategoryAccuracy |  0.11309525\n",
            "\n",
            "Step  10300: Ran 100 train steps in 109.20 secs\n",
            "Step  10300: train CrossEntropyLossWithLogSoftmax |  6.82921696\n",
            "Step  10300: eval  CrossEntropyLossWithLogSoftmax |  6.97144842\n",
            "Step  10300: eval        WeightedCategoryAccuracy |  0.13976377\n",
            "Step  10300: eval  CrossEntropyLossWithLogSoftmax |  7.18680286\n",
            "Step  10300: eval        WeightedCategoryAccuracy |  0.09790209\n",
            "\n",
            "Step  10400: Ran 100 train steps in 101.90 secs\n",
            "Step  10400: train CrossEntropyLossWithLogSoftmax |  6.80126572\n",
            "Step  10400: eval  CrossEntropyLossWithLogSoftmax |  6.41712475\n",
            "Step  10400: eval        WeightedCategoryAccuracy |  0.14955357\n",
            "Step  10400: eval  CrossEntropyLossWithLogSoftmax |  7.33332253\n",
            "Step  10400: eval        WeightedCategoryAccuracy |  0.08499999\n",
            "\n",
            "Step  10500: Ran 100 train steps in 105.36 secs\n",
            "Step  10500: train CrossEntropyLossWithLogSoftmax |  6.78640413\n",
            "Step  10500: eval  CrossEntropyLossWithLogSoftmax |  6.73070908\n",
            "Step  10500: eval        WeightedCategoryAccuracy |  0.14879650\n",
            "Step  10500: eval  CrossEntropyLossWithLogSoftmax |  7.35317612\n",
            "Step  10500: eval        WeightedCategoryAccuracy |  0.11949684\n",
            "\n",
            "Step  10600: Ran 100 train steps in 103.52 secs\n",
            "Step  10600: train CrossEntropyLossWithLogSoftmax |  6.78217983\n",
            "Step  10600: eval  CrossEntropyLossWithLogSoftmax |  6.60017490\n",
            "Step  10600: eval        WeightedCategoryAccuracy |  0.15584415\n",
            "Step  10600: eval  CrossEntropyLossWithLogSoftmax |  6.93119526\n",
            "Step  10600: eval        WeightedCategoryAccuracy |  0.11510792\n",
            "\n",
            "Step  10700: Ran 100 train steps in 101.65 secs\n",
            "Step  10700: train CrossEntropyLossWithLogSoftmax |  6.79119539\n",
            "Step  10700: eval  CrossEntropyLossWithLogSoftmax |  6.89137459\n",
            "Step  10700: eval        WeightedCategoryAccuracy |  0.11845103\n",
            "Step  10700: eval  CrossEntropyLossWithLogSoftmax |  6.79857731\n",
            "Step  10700: eval        WeightedCategoryAccuracy |  0.16279069\n",
            "\n",
            "Step  10800: Ran 100 train steps in 103.42 secs\n",
            "Step  10800: train CrossEntropyLossWithLogSoftmax |  6.81610823\n",
            "Step  10800: eval  CrossEntropyLossWithLogSoftmax |  6.71920395\n",
            "Step  10800: eval        WeightedCategoryAccuracy |  0.14009662\n",
            "Step  10800: eval  CrossEntropyLossWithLogSoftmax |  7.85731268\n",
            "Step  10800: eval        WeightedCategoryAccuracy |  0.10112360\n",
            "\n",
            "Step  10900: Ran 100 train steps in 108.95 secs\n",
            "Step  10900: train CrossEntropyLossWithLogSoftmax |  6.80637932\n",
            "Step  10900: eval  CrossEntropyLossWithLogSoftmax |  6.76085281\n",
            "Step  10900: eval        WeightedCategoryAccuracy |  0.13288289\n",
            "Step  10900: eval  CrossEntropyLossWithLogSoftmax |  7.25015497\n",
            "Step  10900: eval        WeightedCategoryAccuracy |  0.14705883\n",
            "\n",
            "Step  11000: Ran 100 train steps in 133.36 secs\n",
            "Step  11000: train CrossEntropyLossWithLogSoftmax |  6.79085922\n",
            "Step  11000: eval  CrossEntropyLossWithLogSoftmax |  6.99371147\n",
            "Step  11000: eval        WeightedCategoryAccuracy |  0.13051823\n",
            "Step  11000: eval  CrossEntropyLossWithLogSoftmax |  7.04703951\n",
            "Step  11000: eval        WeightedCategoryAccuracy |  0.13750000\n",
            "\n",
            "Step  11100: Ran 100 train steps in 107.37 secs\n",
            "Step  11100: train CrossEntropyLossWithLogSoftmax |  6.79589605\n",
            "Step  11100: eval  CrossEntropyLossWithLogSoftmax |  7.16987228\n",
            "Step  11100: eval        WeightedCategoryAccuracy |  0.11854684\n",
            "Step  11100: eval  CrossEntropyLossWithLogSoftmax |  7.51061916\n",
            "Step  11100: eval        WeightedCategoryAccuracy |  0.14285715\n",
            "\n",
            "Step  11200: Ran 100 train steps in 102.45 secs\n",
            "Step  11200: train CrossEntropyLossWithLogSoftmax |  6.77319622\n",
            "Step  11200: eval  CrossEntropyLossWithLogSoftmax |  7.04703617\n",
            "Step  11200: eval        WeightedCategoryAccuracy |  0.12474011\n",
            "Step  11200: eval  CrossEntropyLossWithLogSoftmax |  6.97903728\n",
            "Step  11200: eval        WeightedCategoryAccuracy |  0.10909091\n",
            "\n",
            "Step  11300: Ran 100 train steps in 101.48 secs\n",
            "Step  11300: train CrossEntropyLossWithLogSoftmax |  6.75348091\n",
            "Step  11300: eval  CrossEntropyLossWithLogSoftmax |  6.70008373\n",
            "Step  11300: eval        WeightedCategoryAccuracy |  0.12040816\n",
            "Step  11300: eval  CrossEntropyLossWithLogSoftmax |  7.02839899\n",
            "Step  11300: eval        WeightedCategoryAccuracy |  0.10526316\n",
            "\n",
            "Step  11400: Ran 100 train steps in 108.04 secs\n",
            "Step  11400: train CrossEntropyLossWithLogSoftmax |  6.75104952\n",
            "Step  11400: eval  CrossEntropyLossWithLogSoftmax |  6.75632238\n",
            "Step  11400: eval        WeightedCategoryAccuracy |  0.14366730\n",
            "Step  11400: eval  CrossEntropyLossWithLogSoftmax |  6.87605810\n",
            "Step  11400: eval        WeightedCategoryAccuracy |  0.14062500\n",
            "\n",
            "Step  11500: Ran 100 train steps in 99.14 secs\n",
            "Step  11500: train CrossEntropyLossWithLogSoftmax |  6.75814819\n",
            "Step  11500: eval  CrossEntropyLossWithLogSoftmax |  6.69581890\n",
            "Step  11500: eval        WeightedCategoryAccuracy |  0.14189190\n",
            "Step  11500: eval  CrossEntropyLossWithLogSoftmax |  7.46703720\n",
            "Step  11500: eval        WeightedCategoryAccuracy |  0.11585365\n",
            "\n",
            "Step  11600: Ran 100 train steps in 104.62 secs\n",
            "Step  11600: train CrossEntropyLossWithLogSoftmax |  6.73714113\n",
            "Step  11600: eval  CrossEntropyLossWithLogSoftmax |  6.66566324\n",
            "Step  11600: eval        WeightedCategoryAccuracy |  0.14986375\n",
            "Step  11600: eval  CrossEntropyLossWithLogSoftmax |  7.14082432\n",
            "Step  11600: eval        WeightedCategoryAccuracy |  0.11801241\n",
            "\n",
            "Step  11700: Ran 100 train steps in 104.73 secs\n",
            "Step  11700: train CrossEntropyLossWithLogSoftmax |  6.73768616\n",
            "Step  11700: eval  CrossEntropyLossWithLogSoftmax |  6.58666325\n",
            "Step  11700: eval        WeightedCategoryAccuracy |  0.17910448\n",
            "Step  11700: eval  CrossEntropyLossWithLogSoftmax |  7.76294518\n",
            "Step  11700: eval        WeightedCategoryAccuracy |  0.11309524\n",
            "\n",
            "Step  11800: Ran 100 train steps in 107.82 secs\n",
            "Step  11800: train CrossEntropyLossWithLogSoftmax |  6.73581028\n",
            "Step  11800: eval  CrossEntropyLossWithLogSoftmax |  6.94463158\n",
            "Step  11800: eval        WeightedCategoryAccuracy |  0.13647643\n",
            "Step  11800: eval  CrossEntropyLossWithLogSoftmax |  7.18121672\n",
            "Step  11800: eval        WeightedCategoryAccuracy |  0.13333333\n",
            "\n",
            "Step  11900: Ran 100 train steps in 101.86 secs\n",
            "Step  11900: train CrossEntropyLossWithLogSoftmax |  6.70598602\n",
            "Step  11900: eval  CrossEntropyLossWithLogSoftmax |  6.65320778\n",
            "Step  11900: eval        WeightedCategoryAccuracy |  0.15270935\n",
            "Step  11900: eval  CrossEntropyLossWithLogSoftmax |  7.38719845\n",
            "Step  11900: eval        WeightedCategoryAccuracy |  0.10497238\n",
            "\n",
            "Step  12000: Ran 100 train steps in 142.34 secs\n",
            "Step  12000: train CrossEntropyLossWithLogSoftmax |  6.74043322\n",
            "Step  12000: eval  CrossEntropyLossWithLogSoftmax |  6.73787689\n",
            "Step  12000: eval        WeightedCategoryAccuracy |  0.14211887\n",
            "Step  12000: eval  CrossEntropyLossWithLogSoftmax |  7.23772573\n",
            "Step  12000: eval        WeightedCategoryAccuracy |  0.14685315\n",
            "\n",
            "Step  12100: Ran 100 train steps in 101.88 secs\n",
            "Step  12100: train CrossEntropyLossWithLogSoftmax |  6.73740339\n",
            "Step  12100: eval  CrossEntropyLossWithLogSoftmax |  6.40668869\n",
            "Step  12100: eval        WeightedCategoryAccuracy |  0.16588783\n",
            "Step  12100: eval  CrossEntropyLossWithLogSoftmax |  6.90772820\n",
            "Step  12100: eval        WeightedCategoryAccuracy |  0.10738256\n",
            "\n",
            "Step  12200: Ran 100 train steps in 108.22 secs\n",
            "Step  12200: train CrossEntropyLossWithLogSoftmax |  6.72135735\n",
            "Step  12200: eval  CrossEntropyLossWithLogSoftmax |  7.00910759\n",
            "Step  12200: eval        WeightedCategoryAccuracy |  0.13152805\n",
            "Step  12200: eval  CrossEntropyLossWithLogSoftmax |  7.16601086\n",
            "Step  12200: eval        WeightedCategoryAccuracy |  0.16058394\n",
            "\n",
            "Step  12300: Ran 100 train steps in 97.19 secs\n",
            "Step  12300: train CrossEntropyLossWithLogSoftmax |  6.71129322\n",
            "Step  12300: eval  CrossEntropyLossWithLogSoftmax |  6.58398628\n",
            "Step  12300: eval        WeightedCategoryAccuracy |  0.13111112\n",
            "Step  12300: eval  CrossEntropyLossWithLogSoftmax |  7.37425518\n",
            "Step  12300: eval        WeightedCategoryAccuracy |  0.12068966\n",
            "\n",
            "Step  12400: Ran 100 train steps in 99.67 secs\n",
            "Step  12400: train CrossEntropyLossWithLogSoftmax |  6.70780087\n",
            "Step  12400: eval  CrossEntropyLossWithLogSoftmax |  6.70933533\n",
            "Step  12400: eval        WeightedCategoryAccuracy |  0.15975103\n",
            "Step  12400: eval  CrossEntropyLossWithLogSoftmax |  7.40128946\n",
            "Step  12400: eval        WeightedCategoryAccuracy |  0.14184397\n",
            "\n",
            "Step  12500: Ran 100 train steps in 106.63 secs\n",
            "Step  12500: train CrossEntropyLossWithLogSoftmax |  6.71687603\n",
            "Step  12500: eval  CrossEntropyLossWithLogSoftmax |  6.82141495\n",
            "Step  12500: eval        WeightedCategoryAccuracy |  0.13763441\n",
            "Step  12500: eval  CrossEntropyLossWithLogSoftmax |  7.39288425\n",
            "Step  12500: eval        WeightedCategoryAccuracy |  0.09271523\n",
            "\n",
            "Step  12600: Ran 100 train steps in 110.16 secs\n",
            "Step  12600: train CrossEntropyLossWithLogSoftmax |  6.69674110\n",
            "Step  12600: eval  CrossEntropyLossWithLogSoftmax |  6.54585457\n",
            "Step  12600: eval        WeightedCategoryAccuracy |  0.17801046\n",
            "Step  12600: eval  CrossEntropyLossWithLogSoftmax |  7.39133167\n",
            "Step  12600: eval        WeightedCategoryAccuracy |  0.08904111\n",
            "\n",
            "Step  12700: Ran 100 train steps in 103.75 secs\n",
            "Step  12700: train CrossEntropyLossWithLogSoftmax |  6.68143892\n",
            "Step  12700: eval  CrossEntropyLossWithLogSoftmax |  6.89702129\n",
            "Step  12700: eval        WeightedCategoryAccuracy |  0.14988814\n",
            "Step  12700: eval  CrossEntropyLossWithLogSoftmax |  6.79224586\n",
            "Step  12700: eval        WeightedCategoryAccuracy |  0.12582782\n",
            "\n",
            "Step  12800: Ran 100 train steps in 102.63 secs\n",
            "Step  12800: train CrossEntropyLossWithLogSoftmax |  6.68084764\n",
            "Step  12800: eval  CrossEntropyLossWithLogSoftmax |  6.78216267\n",
            "Step  12800: eval        WeightedCategoryAccuracy |  0.12955466\n",
            "Step  12800: eval  CrossEntropyLossWithLogSoftmax |  7.00246811\n",
            "Step  12800: eval        WeightedCategoryAccuracy |  0.15503874\n",
            "\n",
            "Step  12900: Ran 100 train steps in 105.43 secs\n",
            "Step  12900: train CrossEntropyLossWithLogSoftmax |  6.68309212\n",
            "Step  12900: eval  CrossEntropyLossWithLogSoftmax |  6.82667828\n",
            "Step  12900: eval        WeightedCategoryAccuracy |  0.14117646\n",
            "Step  12900: eval  CrossEntropyLossWithLogSoftmax |  6.89309978\n",
            "Step  12900: eval        WeightedCategoryAccuracy |  0.10526316\n",
            "\n",
            "Step  13000: Ran 100 train steps in 137.50 secs\n",
            "Step  13000: train CrossEntropyLossWithLogSoftmax |  6.68112087\n",
            "Step  13000: eval  CrossEntropyLossWithLogSoftmax |  6.83366060\n",
            "Step  13000: eval        WeightedCategoryAccuracy |  0.14122137\n",
            "Step  13000: eval  CrossEntropyLossWithLogSoftmax |  7.24629498\n",
            "Step  13000: eval        WeightedCategoryAccuracy |  0.12318840\n",
            "\n",
            "Step  13100: Ran 100 train steps in 111.93 secs\n",
            "Step  13100: train CrossEntropyLossWithLogSoftmax |  6.69796944\n",
            "Step  13100: eval  CrossEntropyLossWithLogSoftmax |  6.32359409\n",
            "Step  13100: eval        WeightedCategoryAccuracy |  0.14187644\n",
            "Step  13100: eval  CrossEntropyLossWithLogSoftmax |  7.12262821\n",
            "Step  13100: eval        WeightedCategoryAccuracy |  0.13043478\n",
            "\n",
            "Step  13200: Ran 100 train steps in 101.96 secs\n",
            "Step  13200: train CrossEntropyLossWithLogSoftmax |  6.67662144\n",
            "Step  13200: eval  CrossEntropyLossWithLogSoftmax |  6.99945450\n",
            "Step  13200: eval        WeightedCategoryAccuracy |  0.13125001\n",
            "Step  13200: eval  CrossEntropyLossWithLogSoftmax |  7.30103874\n",
            "Step  13200: eval        WeightedCategoryAccuracy |  0.11111111\n",
            "\n",
            "Step  13300: Ran 100 train steps in 109.62 secs\n",
            "Step  13300: train CrossEntropyLossWithLogSoftmax |  6.68030453\n",
            "Step  13300: eval  CrossEntropyLossWithLogSoftmax |  6.75102234\n",
            "Step  13300: eval        WeightedCategoryAccuracy |  0.12927756\n",
            "Step  13300: eval  CrossEntropyLossWithLogSoftmax |  7.66519403\n",
            "Step  13300: eval        WeightedCategoryAccuracy |  0.09876544\n",
            "\n",
            "Step  13400: Ran 100 train steps in 117.48 secs\n",
            "Step  13400: train CrossEntropyLossWithLogSoftmax |  6.71529579\n",
            "Step  13400: eval  CrossEntropyLossWithLogSoftmax |  6.51831818\n",
            "Step  13400: eval        WeightedCategoryAccuracy |  0.15690377\n",
            "Step  13400: eval  CrossEntropyLossWithLogSoftmax |  6.85810757\n",
            "Step  13400: eval        WeightedCategoryAccuracy |  0.13533835\n",
            "\n",
            "Step  13500: Ran 100 train steps in 108.75 secs\n",
            "Step  13500: train CrossEntropyLossWithLogSoftmax |  6.67509317\n",
            "Step  13500: eval  CrossEntropyLossWithLogSoftmax |  6.45373869\n",
            "Step  13500: eval        WeightedCategoryAccuracy |  0.16470587\n",
            "Step  13500: eval  CrossEntropyLossWithLogSoftmax |  6.80448580\n",
            "Step  13500: eval        WeightedCategoryAccuracy |  0.16129032\n",
            "\n",
            "Step  13600: Ran 100 train steps in 100.02 secs\n",
            "Step  13600: train CrossEntropyLossWithLogSoftmax |  6.68319702\n",
            "Step  13600: eval  CrossEntropyLossWithLogSoftmax |  6.84440708\n",
            "Step  13600: eval        WeightedCategoryAccuracy |  0.14830509\n",
            "Step  13600: eval  CrossEntropyLossWithLogSoftmax |  7.23974848\n",
            "Step  13600: eval        WeightedCategoryAccuracy |  0.11656442\n",
            "\n",
            "Step  13700: Ran 100 train steps in 111.57 secs\n",
            "Step  13700: train CrossEntropyLossWithLogSoftmax |  6.69680405\n",
            "Step  13700: eval  CrossEntropyLossWithLogSoftmax |  6.49592304\n",
            "Step  13700: eval        WeightedCategoryAccuracy |  0.17441860\n",
            "Step  13700: eval  CrossEntropyLossWithLogSoftmax |  7.37974548\n",
            "Step  13700: eval        WeightedCategoryAccuracy |  0.12121212\n",
            "\n",
            "Step  13800: Ran 100 train steps in 100.59 secs\n",
            "Step  13800: train CrossEntropyLossWithLogSoftmax |  6.65411186\n",
            "Step  13800: eval  CrossEntropyLossWithLogSoftmax |  6.62929630\n",
            "Step  13800: eval        WeightedCategoryAccuracy |  0.13429752\n",
            "Step  13800: eval  CrossEntropyLossWithLogSoftmax |  7.53784561\n",
            "Step  13800: eval        WeightedCategoryAccuracy |  0.10204081\n",
            "\n",
            "Step  13900: Ran 100 train steps in 103.68 secs\n",
            "Step  13900: train CrossEntropyLossWithLogSoftmax |  6.66868353\n",
            "Step  13900: eval  CrossEntropyLossWithLogSoftmax |  6.73684072\n",
            "Step  13900: eval        WeightedCategoryAccuracy |  0.15217391\n",
            "Step  13900: eval  CrossEntropyLossWithLogSoftmax |  7.17876625\n",
            "Step  13900: eval        WeightedCategoryAccuracy |  0.10596026\n",
            "\n",
            "Step  14000: Ran 100 train steps in 133.54 secs\n",
            "Step  14000: train CrossEntropyLossWithLogSoftmax |  6.65213871\n",
            "Step  14000: eval  CrossEntropyLossWithLogSoftmax |  6.71073198\n",
            "Step  14000: eval        WeightedCategoryAccuracy |  0.14347824\n",
            "Step  14000: eval  CrossEntropyLossWithLogSoftmax |  6.91712713\n",
            "Step  14000: eval        WeightedCategoryAccuracy |  0.17187500\n",
            "\n",
            "Step  14100: Ran 100 train steps in 106.11 secs\n",
            "Step  14100: train CrossEntropyLossWithLogSoftmax |  6.63704777\n",
            "Step  14100: eval  CrossEntropyLossWithLogSoftmax |  6.89774370\n",
            "Step  14100: eval        WeightedCategoryAccuracy |  0.11700182\n",
            "Step  14100: eval  CrossEntropyLossWithLogSoftmax |  6.88337040\n",
            "Step  14100: eval        WeightedCategoryAccuracy |  0.13690478\n",
            "\n",
            "Step  14200: Ran 100 train steps in 110.55 secs\n",
            "Step  14200: train CrossEntropyLossWithLogSoftmax |  6.64303446\n",
            "Step  14200: eval  CrossEntropyLossWithLogSoftmax |  6.48449421\n",
            "Step  14200: eval        WeightedCategoryAccuracy |  0.15505618\n",
            "Step  14200: eval  CrossEntropyLossWithLogSoftmax |  6.81127310\n",
            "Step  14200: eval        WeightedCategoryAccuracy |  0.11250000\n",
            "\n",
            "Step  14300: Ran 100 train steps in 101.47 secs\n",
            "Step  14300: train CrossEntropyLossWithLogSoftmax |  6.64049053\n",
            "Step  14300: eval  CrossEntropyLossWithLogSoftmax |  6.95628643\n",
            "Step  14300: eval        WeightedCategoryAccuracy |  0.14341846\n",
            "Step  14300: eval  CrossEntropyLossWithLogSoftmax |  6.65022659\n",
            "Step  14300: eval        WeightedCategoryAccuracy |  0.14285716\n",
            "\n",
            "Step  14400: Ran 100 train steps in 104.17 secs\n",
            "Step  14400: train CrossEntropyLossWithLogSoftmax |  6.64829206\n",
            "Step  14400: eval  CrossEntropyLossWithLogSoftmax |  6.79833412\n",
            "Step  14400: eval        WeightedCategoryAccuracy |  0.11040000\n",
            "Step  14400: eval  CrossEntropyLossWithLogSoftmax |  7.39533806\n",
            "Step  14400: eval        WeightedCategoryAccuracy |  0.13953486\n",
            "\n",
            "Step  14500: Ran 100 train steps in 100.33 secs\n",
            "Step  14500: train CrossEntropyLossWithLogSoftmax |  6.65152884\n",
            "Step  14500: eval  CrossEntropyLossWithLogSoftmax |  6.69831085\n",
            "Step  14500: eval        WeightedCategoryAccuracy |  0.14170042\n",
            "Step  14500: eval  CrossEntropyLossWithLogSoftmax |  6.96015453\n",
            "Step  14500: eval        WeightedCategoryAccuracy |  0.11538462\n",
            "\n",
            "Step  14600: Ran 100 train steps in 104.65 secs\n",
            "Step  14600: train CrossEntropyLossWithLogSoftmax |  6.62069273\n",
            "Step  14600: eval  CrossEntropyLossWithLogSoftmax |  6.76783276\n",
            "Step  14600: eval        WeightedCategoryAccuracy |  0.13793103\n",
            "Step  14600: eval  CrossEntropyLossWithLogSoftmax |  7.21506310\n",
            "Step  14600: eval        WeightedCategoryAccuracy |  0.11320755\n",
            "\n",
            "Step  14700: Ran 100 train steps in 101.76 secs\n",
            "Step  14700: train CrossEntropyLossWithLogSoftmax |  6.63395452\n",
            "Step  14700: eval  CrossEntropyLossWithLogSoftmax |  7.11406136\n",
            "Step  14700: eval        WeightedCategoryAccuracy |  0.11722912\n",
            "Step  14700: eval  CrossEntropyLossWithLogSoftmax |  6.80546856\n",
            "Step  14700: eval        WeightedCategoryAccuracy |  0.16806725\n",
            "\n",
            "Step  14800: Ran 100 train steps in 112.00 secs\n",
            "Step  14800: train CrossEntropyLossWithLogSoftmax |  6.60986614\n",
            "Step  14800: eval  CrossEntropyLossWithLogSoftmax |  6.75006771\n",
            "Step  14800: eval        WeightedCategoryAccuracy |  0.15098038\n",
            "Step  14800: eval  CrossEntropyLossWithLogSoftmax |  7.15527391\n",
            "Step  14800: eval        WeightedCategoryAccuracy |  0.11888111\n",
            "\n",
            "Step  14900: Ran 100 train steps in 102.51 secs\n",
            "Step  14900: train CrossEntropyLossWithLogSoftmax |  6.61210871\n",
            "Step  14900: eval  CrossEntropyLossWithLogSoftmax |  6.63505173\n",
            "Step  14900: eval        WeightedCategoryAccuracy |  0.17403316\n",
            "Step  14900: eval  CrossEntropyLossWithLogSoftmax |  7.10656071\n",
            "Step  14900: eval        WeightedCategoryAccuracy |  0.11224490\n",
            "\n",
            "Step  15000: Ran 100 train steps in 136.26 secs\n",
            "Step  15000: train CrossEntropyLossWithLogSoftmax |  6.61435127\n",
            "Step  15000: eval  CrossEntropyLossWithLogSoftmax |  6.84587431\n",
            "Step  15000: eval        WeightedCategoryAccuracy |  0.13704497\n",
            "Step  15000: eval  CrossEntropyLossWithLogSoftmax |  7.12461567\n",
            "Step  15000: eval        WeightedCategoryAccuracy |  0.11888112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If Model directory not already present with the trained model weights, uncomment and run the previous line and this line\n",
        "# In case Basic Transformer Training session crashes\n",
        "# training_loop.load_checkpoint(directory=output_dir, filename=\"model.pkl.gz\")"
      ],
      "metadata": {
        "id": "fE8XQtup-src"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Transformer\n",
        "# model.init_from_file(\"./Model/model.pkl.gz\")"
      ],
      "metadata": {
        "id": "SwwdNibtiHsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigger Transformer\n",
        "model.init_from_file(\"./Model-1/model.pkl.gz\")"
      ],
      "metadata": {
        "id": "-_T3uCFSrPmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Testing (Trax)"
      ],
      "metadata": {
        "id": "TbYDUMNUjdyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Greedy Search"
      ],
      "metadata": {
        "id": "v6X0CZo4kJOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At every step of prediction, we feed in the input sequence and the predicted translated part upto that point. Based on this, the model predicts the next token id given the previous were the ones predicted till that point. We have `temperature=0.0`, so it will not sample the next token instead it will choose the one with maximum probability. "
      ],
      "metadata": {
        "id": "Y8HbKJVok0WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_symbol(model, input_tokens, cur_output_tokens, temperature):\n",
        "    token_length = len(cur_output_tokens)\n",
        "    padded_length = 60\n",
        "    padded = cur_output_tokens + [0] * (padded_length - token_length) \n",
        "    padded_with_batch = np.expand_dims(padded, axis=0)\n",
        "    output, _ = model((input_tokens, padded_with_batch))   \n",
        "    log_probs = output[0, token_length, :]\n",
        "    symbol = int(tl.logsoftmax_sample(log_probs, temperature))\n",
        "    return symbol, float(log_probs[symbol])"
      ],
      "metadata": {
        "id": "Eww1p5UpuXQp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_decode(input_sentence, model = None, temperature=0.0):\n",
        "    input_tokens = tokenize(input_sentence, sp_en_bpe)\n",
        "    cur_output_tokens = []\n",
        "    cur_output = 0  \n",
        "    EOS = 1\n",
        "    while cur_output != EOS: \n",
        "        cur_output, log_prob = next_symbol(model, input_tokens, cur_output_tokens, temperature)\n",
        "        cur_output_tokens.append(cur_output) \n",
        "    sentence = detokenize(cur_output_tokens, sp_ben_bpe)\n",
        "    return cur_output_tokens, log_prob, sentence"
      ],
      "metadata": {
        "id": "qph6-_sh8Wp6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode_test(sentence, model=None):  \n",
        "    _,_, translated_sentence = sampling_decode(sentence, model)   \n",
        "    return translated_sentence"
      ],
      "metadata": {
        "id": "wRRrPFnu8fk2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'I love you.'\n",
        "translated_sentence = greedy_decode_test(sentence, model)\n",
        "print(\"English: \", sentence)\n",
        "print(\"Bengali: \", translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaxploMw87fW",
        "outputId": "d5c3dd77-89e1-4067-c621-38b307f886ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  I love you.\n",
            "Bengali:   ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Minimum Bayes-Risk Decoding"
      ],
      "metadata": {
        "id": "ZiRPbKY_kWVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We sample multiple sentence(with non-zero `temperature`). Then, we calculate the similarity score(`rougel_similarity`) of all of the sampled sentences with every other. Then we take the average of it to be the score of each sentence. The one with the highest score is selected."
      ],
      "metadata": {
        "id": "lYj1v3B0oOej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(sentence, n_samples, model=None, temperature=0.6):\n",
        "    samples, log_probs = [], []\n",
        "    for _ in range(n_samples):\n",
        "        sample, logp, _ = sampling_decode(sentence, model, temperature)\n",
        "        samples.append(sample)\n",
        "        log_probs.append(logp)\n",
        "    return samples, log_probs"
      ],
      "metadata": {
        "id": "Y1y-HuYlHKek"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use ROUGE score as the similarity metric for two sentences.\n",
        "$$ROUGE\\enspace score= 2* \\frac{(precision * recall)}{(precision + recall)}$$"
      ],
      "metadata": {
        "id": "oTdO1XtssZ5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge1_similarity(system, reference):\n",
        "    sys_counter = Counter(system)\n",
        "    ref_counter = Counter(reference)\n",
        "    overlap = 0\n",
        "    for token in sys_counter:\n",
        "        token_count_sys = sys_counter[token]\n",
        "        token_count_ref = ref_counter[token]\n",
        "        overlap += min(token_count_ref, token_count_sys)\n",
        "    precision = overlap / sum(sys_counter.values())\n",
        "    recall = overlap / sum(ref_counter.values())\n",
        "    if precision + recall != 0:\n",
        "        rouge1_score = 2 * ((precision * recall)/(precision + recall))\n",
        "    else:\n",
        "        rouge1_score = 0     \n",
        "    return rouge1_score"
      ],
      "metadata": {
        "id": "WBvt4DUpp7QV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_avg_overlap(samples, log_probs):\n",
        "    scores = {}\n",
        "    for index_candidate, candidate in enumerate(samples):    \n",
        "        overlap, weight_sum = 0.0, 0.0\n",
        "        for index_sample, (sample, logp) in enumerate(zip(samples, log_probs)):           \n",
        "            if index_candidate == index_sample:\n",
        "                continue\n",
        "            sample_p = float(np.exp(logp))\n",
        "            weight_sum += sample_p\n",
        "            sample_overlap = rouge1_similarity(candidate, sample)\n",
        "            overlap += sample_p * sample_overlap\n",
        "        score = overlap / weight_sum\n",
        "        scores[index_candidate] = score\n",
        "    return scores"
      ],
      "metadata": {
        "id": "esfFWkSEpKry"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mbr_decode(sentence, n_samples, model=None, temperature=0.6):\n",
        "    samples, log_probs = generate_samples(sentence, n_samples, model, temperature)\n",
        "    scores = weighted_avg_overlap(samples, log_probs)\n",
        "    max_score_key = max(scores, key=scores.get)\n",
        "    translated_sentence = detokenize(samples[max_score_key], sp_ben_bpe)\n",
        "    return (translated_sentence, max_score_key, scores)"
      ],
      "metadata": {
        "id": "PhD9TykMqenD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"I love you.\"\n",
        "translated_sentence = mbr_decode(sentence, 4, model, 1)\n",
        "print(\"English: \", sentence)\n",
        "print(\"Bengali: \", translated_sentence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6aUMvsqs9jZ",
        "outputId": "9a675d12-ca8c-4cc0-af4e-c2739d590925"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  I love you.\n",
            "Bengali:       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"research has shown that exercise also helps in removing stress.\"\n",
        "translated_sentence = mbr_decode(sentence, 4, model, 1)\n",
        "print(\"English: \", sentence)\n",
        "print(\"Bengali: \", translated_sentence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOgTxVVY90Sm",
        "outputId": "129ba071-09f0-4531-94f0-1fcf6d62d8d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English:  research has shown that exercise also helps in removing stress.\n",
            "Bengali:       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. LSTM Based Models"
      ],
      "metadata": {
        "id": "cOptu91rcLPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 LSTM with Attention (Trax)"
      ],
      "metadata": {
        "id": "sIye4G9bcfcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the inputs for `AttentionQKV` layer."
      ],
      "metadata": {
        "id": "tH2I6S7Uq71J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_attention_input(encoder_activations, decoder_activations, inputs):\n",
        "    keys = encoder_activations\n",
        "    values = encoder_activations\n",
        "    queries = decoder_activations\n",
        "    mask = 1-fnp.equal(inputs, 0)\n",
        "    mask = fnp.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n",
        "    # Mask is of dimension [batch_dim, attention_heads, decoder_dim(since, if a position is not padded all the elements in decoder_dim contributes, else none), padded_length]\n",
        "    mask = mask + fnp.zeros((1, 1, decoder_activations.shape[1], 1))\n",
        "    return queries, keys, values, mask"
      ],
      "metadata": {
        "id": "iFiOD3QycU2B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement the full architechture below"
      ],
      "metadata": {
        "id": "riWooxxMrC4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTMAttn(input_vocab_size=32000,\n",
        "            target_vocab_size=32000,\n",
        "            d_model=512,\n",
        "            n_encoder_layers=3,\n",
        "            n_decoder_layers=3,\n",
        "            n_attention_heads=2,\n",
        "            attention_dropout=0.3,\n",
        "            mode='train'):\n",
        "    \n",
        "    input_encoder = tl.Serial(tl.Embedding(vocab_size=input_vocab_size, d_feature=d_model),\n",
        "                              [tl.LSTM(d_model) for _ in range(n_encoder_layers)])\n",
        "    pre_attention_decoder = pre_attention_decoder = tl.Serial(tl.ShiftRight(mode=mode), # Teacher Forcing\n",
        "                                                              tl.Embedding(vocab_size=target_vocab_size, d_feature=d_model),\n",
        "                                                              tl.LSTM(d_model))\n",
        "    model = tl.Serial(\n",
        "        tl.Select([0, 1, 0, 1]),\n",
        "        tl.Parallel(input_encoder, pre_attention_decoder),\n",
        "        tl.Fn('PrepareAttentionInput', prepare_attention_input, n_out=4),\n",
        "        tl.Residual(tl.AttentionQKV(d_model, n_heads=n_attention_heads, dropout=attention_dropout, mode=mode)),\n",
        "        tl.Select([0, 2]),\n",
        "        [tl.LSTM(d_model) for _ in range(n_decoder_layers)],\n",
        "        tl.Dense(target_vocab_size),\n",
        "        tl.LogSoftmax())\n",
        "    return model"
      ],
      "metadata": {
        "id": "333KO_ruknCP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMAttn()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kisa7dPdrohi",
        "outputId": "5a67b841-23ef-4f90-f812-ff9b1c70c258"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Serial_in2_out2[\n",
              "  Select[0,1,0,1]_in2_out4\n",
              "  Parallel_in2_out2[\n",
              "    Serial[\n",
              "      Embedding_32000_512\n",
              "      LSTM_512\n",
              "      LSTM_512\n",
              "      LSTM_512\n",
              "    ]\n",
              "    Serial[\n",
              "      Serial[\n",
              "        ShiftRight(1)\n",
              "      ]\n",
              "      Embedding_32000_512\n",
              "      LSTM_512\n",
              "    ]\n",
              "  ]\n",
              "  PrepareAttentionInput_in3_out4\n",
              "  Serial_in4_out2[\n",
              "    Branch_in4_out3[\n",
              "      None\n",
              "      Serial_in4_out2[\n",
              "        _in4_out4\n",
              "        Serial_in4_out2[\n",
              "          Parallel_in3_out3[\n",
              "            Dense_512\n",
              "            Dense_512\n",
              "            Dense_512\n",
              "          ]\n",
              "          PureAttention_in4_out2\n",
              "          Dense_512\n",
              "        ]\n",
              "        _in2_out2\n",
              "      ]\n",
              "    ]\n",
              "    Add_in2\n",
              "  ]\n",
              "  Select[0,2]_in3_out2\n",
              "  LSTM_512\n",
              "  LSTM_512\n",
              "  LSTM_512\n",
              "  Dense_32000\n",
              "  LogSoftmax\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Training (Trax)"
      ],
      "metadata": {
        "id": "lPyN8FuCuF9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting our data generator to be fed to the training."
      ],
      "metadata": {
        "id": "j_-qsqKquF9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(43)\n",
        "train_generator = trax.data.inputs.add_loss_weights(train_data_gen, id_to_mask= sp_en_bpe.pad_id())\n",
        "train_dev_generator = trax.data.inputs.add_loss_weights(train_dev_data_gen, id_to_mask= sp_en_bpe.pad_id())\n",
        "test_val_generator = trax.data.inputs.add_loss_weights(test_val_data_gen, id_to_mask= sp_en_bpe.pad_id())"
      ],
      "metadata": {
        "id": "BVWNta6YuF9R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up `train_task` on which our model will be trained. We use:\n",
        "- `loss function = CrossEntropyLossWithLogSotmax`\n",
        "- `optimizer = Adam with learning rate 0.01`\n",
        "- `learning rate schedule = warm up and square root decay`."
      ],
      "metadata": {
        "id": "g3-LAkdpuF9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_task = training.TrainTask(labeled_data= train_generator, \n",
        "                                loss_layer= tl.CrossEntropyLossWithLogSoftmax(),\n",
        "                                optimizer= trax.optimizers.Adam(0.01),\n",
        "                                lr_schedule= trax.lr.warmup_and_rsqrt_decay(1000, 0.01),\n",
        "                                n_steps_per_checkpoint= 100,\n",
        "                                n_steps_per_permanent_checkpoint= 1000)"
      ],
      "metadata": {
        "id": "qhRE-YiLuF9T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up `eval_task` for evaluating our model performance on `train_dev_data` and `test_val_data`. We monitor quite a few metrics on our evaluation datasets `train_dev_data` and `test_val_data` which are:\n",
        "- `CrossEntropyLossWithLogSoftmax`\n",
        "- `WeightedCategoryAccuracy`."
      ],
      "metadata": {
        "id": "J9nPlt6duF9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_train_dev_task = training.EvalTask(labeled_data=train_dev_generator,\n",
        "                              metrics=[tl.CrossEntropyLossWithLogSoftmax(), tl.WeightedCategoryAccuracy()])"
      ],
      "metadata": {
        "id": "mIiJaSSauF9U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_test_val_task = training.EvalTask(labeled_data=test_val_generator,\n",
        "                              metrics=[tl.CrossEntropyLossWithLogSoftmax(), tl.WeightedCategoryAccuracy()])"
      ],
      "metadata": {
        "id": "IhNIZ1YluF9U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the `training_loop` for training our model."
      ],
      "metadata": {
        "id": "EGWlNci_uF9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jax.default_backend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XkONYtdKknzX",
        "outputId": "be80eea4-1120-45b9-eb94-e6db402eb2aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = './Model-2'\n",
        "training_loop = training.Loop(model,\n",
        "                              train_task,\n",
        "                              eval_tasks=[eval_train_dev_task, eval_test_val_task],\n",
        "                              output_dir=output_dir)"
      ],
      "metadata": {
        "id": "3la2erzfuF9W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop.run(15000)"
      ],
      "metadata": {
        "id": "Isxyc8JOuF9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Couldn't even start training as RAM usage exceeds in Google Colab and it keeps on crashing."
      ],
      "metadata": {
        "id": "9QC7Y5jgqkwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If Model directory not already present with the trained model weights, uncomment and run the previous line and this line\n",
        "# In case LSTM Attention Training session crashes\n",
        "# training_loop.load_checkpoint(directory=output_dir, filename=\"model.pkl.gz\")"
      ],
      "metadata": {
        "id": "posnEh6euF9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HqHnaVza5SjN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4IkuxdSO_UNC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}